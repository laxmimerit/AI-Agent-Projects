{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2B Code Sandbox with Google Gemini\n",
    "Execute AI-generated Python code in a secure sandbox environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"E2B Code Sandbox with Google Gemini.\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from e2b_code_interpreter import Sandbox\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandbox created\n"
     ]
    }
   ],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "sbx = Sandbox.create()\n",
    "print(\"Sandbox created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_info(file_path):\n",
    "    \"\"\"Get basic dataset info.\"\"\"\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path, nrows=3)\n",
    "    else:\n",
    "        df = pd.read_excel(file_path, nrows=3)\n",
    "\n",
    "    return f\"Columns: {list(df.columns)}\\nSample data:\\n{df.to_string()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def upload_file(local_file_path: str):\n",
    "    \"\"\"Upload a data file to the E2B sandbox for analysis.\n",
    "    \n",
    "    Use this tool to upload CSV or Excel files before analyzing them.\n",
    "    The file will be uploaded to the sandbox and the sandbox path will be returned.\n",
    "    \n",
    "    Args:\n",
    "        local_file_path: Local path to the file (e.g., \"./data/IMDB-Movie-Data.csv\")\n",
    "        \n",
    "    Returns:\n",
    "        Success message with sandbox_path and dataset_info\n",
    "        \n",
    "    Example:\n",
    "        local_file_path = \"./data/titanic.csv\"\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_file_path):\n",
    "        return f\"Error: File not found at {local_file_path}\"\n",
    "    \n",
    "    filename = os.path.basename(local_file_path)\n",
    "    \n",
    "    with open(local_file_path, \"rb\") as f:\n",
    "        sandbox_file = sbx.files.write(f\"data/{filename}\", f)\n",
    "    \n",
    "    dataset_info = get_dataset_info(local_file_path)\n",
    "    \n",
    "    return f\"File uploaded successfully!\\nSandbox path: {sandbox_file.path}\\n{dataset_info}\"\n",
    "\n",
    "@tool\n",
    "def run_python_code(code: str):\n",
    "    \"\"\"Execute Python code in E2B sandbox and save chart outputs.\n",
    "    \n",
    "    IMPORTANT: The code parameter must be valid, executable Python code only.\n",
    "    - Do NOT include markdown formatting (no ```python or ```)\n",
    "    - Do NOT include explanations or comments outside the code\n",
    "    - Include all necessary imports (pandas, matplotlib, numpy, etc.)\n",
    "    - Use the exact dataset path provided in the system prompt\n",
    "    - For visualizations, end with: display(plt.gcf())\n",
    "\n",
    "    Args:\n",
    "        code: Valid executable Python code as a plain string\n",
    "\n",
    "    Returns:\n",
    "        Execution result or error message\n",
    "        \n",
    "    Example:\n",
    "        code = \"import pandas as pd\\\\nimport matplotlib.pyplot as plt\\\\ndf = pd.read_csv('/path/to/data.csv')\\\\nplt.plot(df['x'], df['y'])\\\\ndisplay(plt.gcf())\"\n",
    "    \"\"\"\n",
    "    print('Running code in sandbox....')\n",
    "    execution = sbx.run_code(code)\n",
    "    print('Code execution finished!')\n",
    "\n",
    "    if execution.error:\n",
    "        return f\"Error: {execution.error.name}\\nValue: {execution.error.value}\"\n",
    "\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    timestamp = int(time.time())\n",
    "    for idx, result in enumerate(execution.results):\n",
    "        if result.png:\n",
    "            filename = f'images/{timestamp}_chart-{idx}.png'\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(base64.b64decode(result.png))\n",
    "            results.append(f'Chart saved to {filename}')\n",
    "\n",
    "    return \"\\n\".join(results) if results else \"Code executed successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent and Execute Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code in sandbox....\n",
      "Code execution finished!\n",
      "\n",
      "Response:\n",
      "I have created a line chart showing the average movie ratings over the years.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a data analysis assistant with access to filesystem search, file upload, and Python code execution tools.\n",
    "\n",
    "WORKFLOW:\n",
    "1. First, use filesystem search tools to locate the requested data file in the local filesystem\n",
    "2. Once you find the file path, use the upload_file tool to upload it to the sandbox\n",
    "3. The upload_file tool will return the sandbox path and dataset information\n",
    "4. Finally, use run_python_code tool to analyze the data using the sandbox path\n",
    "\n",
    "CRITICAL RULES for run_python_code:\n",
    "1. Generate ONLY executable Python code - no explanations, no markdown, no comments outside code\n",
    "2. Import all required libraries (pandas, matplotlib, numpy, etc.)\n",
    "3. Load data from the sandbox path returned by upload_file (e.g., /home/user/data/filename.csv)\n",
    "4. For plots, MUST end with: display(plt.gcf())\n",
    "5. Use the run_python_code tool with ONLY the code string\n",
    "\n",
    "Example workflow:\n",
    "- User asks: \"Analyze IMDB movie data\"\n",
    "- You search filesystem for IMDB related files\n",
    "- You find \"./data/IMDB-Movie-Data.csv\"\n",
    "- You upload it using upload_file tool\n",
    "- You get sandbox path like \"/home/user/data/IMDB-Movie-Data.csv\"\n",
    "- You generate Python code using that exact sandbox path\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      "I am unable to upload the file `/IMDB-Movie-Data.csv` as the `upload_file` tool reports that the file is not found, even though `glob_search` indicates its presence. This prevents me from proceeding with the analysis.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import FilesystemFileSearchMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[upload_file, run_python_code],\n",
    "    system_prompt=system_prompt,\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[FilesystemFileSearchMiddleware(\n",
    "        root_path=\"./data\",\n",
    "        use_ripgrep=True,\n",
    "        max_file_size_mb=100\n",
    "    )]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"default\"}}\n",
    "\n",
    "query = \"Upload ./data/IMDB-Movie-Data.csv and create a line chart showing average ratings over years\"\n",
    "\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=query)]}, config=config)\n",
    "\n",
    "response = result['messages'][-1].text\n",
    "print(f\"\\nResponse:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
