{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Long-Term Memory\n",
    "\n",
    "Long-term memory persists user facts across sessions using stores with semantic search.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Store persists data across sessions and threads\n",
    "- PostgresStore with embeddings enables semantic search\n",
    "- Tools access store via runtime.store\n",
    "- Context provides user identification\n",
    "- Namespaces organize memories hierarchically\n",
    "- Semantic search finds relevant memories by meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52547b",
   "metadata": {},
   "source": [
    "## Memory Comparison\n",
    "\n",
    "| Type | Storage | Use Case | Persistence |\n",
    "|------|---------|----------|-------------|\n",
    "| **Short-term** | Checkpointer | Conversation history | Session |\n",
    "| **Long-term** | Store | User preferences, facts | Cross-session |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with long-term memory.\n",
    "\n",
    "MEMORY TOOLS USAGE:\n",
    "\n",
    "save_user_memory - Save when user shares NEW information:\n",
    "- Food preferences (diet, likes, dislikes, allergies)\n",
    "- Work information (role, company, interests)  \n",
    "- Hobbies and personal interests\n",
    "- Location and timezone preferences\n",
    "\n",
    "get_user_memory - Retrieve specific category:\n",
    "- When answering questions about past preferences\n",
    "- When user asks \"what do you know about me?\"\n",
    "- When making personalized recommendations\n",
    "\n",
    "web_search - Retrieve Real-time information\n",
    "- When user ask about news or latest update\n",
    "- When user ask about real-time information\n",
    "\n",
    "GUIDELINES:\n",
    "- Always save when user shares personal information\n",
    "- Use stored preferences to personalize responses\n",
    "- Be conversational and natural\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Setup PostgresStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='gemini-embedding-001')\n",
    "\n",
    "def embed(texts: list[str]):\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "pg_conn = psycopg.connect(os.getenv(\"POSTGRESQL_URL\"), autocommit=True, prepare_threshold=0)\n",
    "store = PostgresStore(pg_conn, index={\"embed\": embed, \"dims\": 768})\n",
    "store.setup()\n",
    "\n",
    "# Context schema for user identification\n",
    "class CustomContext(BaseModel):\n",
    "    user_id: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Memory Tools with ToolRuntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "@tool\ndef save_user_memory(category: str, information: dict, runtime: ToolRuntime[CustomContext]):\n    \"\"\"Save user preference or information to long-term memory.\n    \n    Args:\n        category: Category of information (e.g., 'food', 'work', 'hobbies', 'location')\n        information: Dictionary containing the information to save\n        \n    Examples:\n        category='food', information={'diet': 'vegetarian', 'likes': ['pasta', 'pizza']}\n        category='work', information={'role': 'Data Scientist', 'interests': ['AI', 'ML']}\n    \"\"\"\n    store = runtime.store\n    user_id = runtime.context.user_id\n    namespace = (user_id, \"preferences\")\n    \n    store.put(namespace, category, information)\n    return f\"Saved {category} preferences for {user_id}\"\n\n@tool\ndef get_user_memory(category: str, runtime: ToolRuntime[CustomContext]):\n    \"\"\"Retrieve user preference or information from long-term memory.\n    \n    Args:\n        category: Category of information to retrieve (e.g., 'food', 'work', 'hobbies')\n        \n    Returns:\n        Stored information for the category or \"not found\" message\n    \"\"\"\n    store = runtime.store\n    user_id = runtime.context.user_id\n    namespace = (user_id, \"preferences\")\n    \n    item = store.get(namespace, category)\n    if item:\n        return f\"{category}: {item.value}\"\n    return f\"No '{category}' information found\""
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Agent with Long-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_saver = PostgresSaver(pg_conn)\n",
    "pg_saver.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_user_memory, get_user_memory, base_tools.web_search],\n",
    "    checkpointer=pg_saver,\n",
    "    store=store,\n",
    "    context_schema=CustomContext,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Save User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great! I've saved that you're a vegetarian and love pasta, pizza, and Italian food. I'll keep that in mind for future recommendations!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save user information\n",
    "config = {\"configurable\": {\"thread_id\": \"session_1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"I'm a vegetarian and I love pasta, pizza, and Italian food\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thanks for sharing! I've noted that you work as a Data Scientist and are interested in AI and machine learning. I'll remember this for our future conversations.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save work information\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"I work as a Data Scientist and I'm interested in AI and machine learning\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Retrieve in New Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'You are vegetarian and like pasta, pizza, and Italian food.',\n",
       "  'extras': {'signature': 'CrECAXLI2nx3m5+23z8fscSuFNgT0I0ZaFJYbNeD23/pH/yfVDdb1KCeG70NZmkPu/0TTOZTqCen9IcBRnBHTo3WL+R2c4ydT4xXCyl2exuKCOnCMKpIFS/dCmljt6lc934mcips0QLdO3pgKXotF8J1/tBwYByijiTvxGB1S6wT0cij3KVfwuvRdAAZU/1L8UctpTFJMwYly195a4DQx4JeYE0O5dX8Tn09V0sC6IIjDj7DI1sNPDCJSbJgUd8cN1zyi9HqNb/COVZAZ3ti8zBBM4Eq8r19Fuoz4diQAB1GDGeoml6BbUtfeAAedumF4dDJcQ8fK+o0Y5uhz1iT1NycNh6ZgZxpqUYAeLKq1G+Xvu/vbq/dMRIaxzEn6AGxHfyyr7l9utgwZRPd32kR8gDk1Qo='}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New thread - different conversation, but same user\n",
    "new_config = {\"configurable\": {\"thread_id\": \"session_2\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"What do you know about my food preferences?\")]\n",
    "}, config=new_config, context=CustomContext(user_id=\"user_123\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on your preference for vegetarian Italian food, here are a couple of options I found:\\n\\n1.  **Olive Garden Italian Restaurants**: They have a dedicated section on their website for vegetarian and vegan options, and you can view their specific vegetarian and vegan menu. They define vegetarian as not including meat, stock, gelatin, or rennet from an animal.\\n\\n2.  **Bellino Ristorante Italiano (Corpus Christi, Texas)**: This restaurant offers authentic Italian and Sicilian cuisine and mentions having traditional Sicilian meat, fish, and vegetarian dishes, as well as freshly-prepared pasta with vegetarian, vegan, and gluten-free options.\\n\\nSince I don't know your current location, these are general suggestions. If you provide a city or area, I could try to find more localized options.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask for recommendations based on stored preferences\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Can you recommend a restaurant for me? use web search\")]\n",
    "}, config=new_config, context=CustomContext(user_id=\"user_123\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food: {'diet': 'vegetarian', 'likes': ['pasta', 'pizza', 'Italian food']}\n",
      "work: {'role': 'Data Scientist', 'interests': ['AI', 'machine learning']}\n"
     ]
    }
   ],
   "source": [
    "# Direct store access for semantic search\n",
    "namespace = (\"user_123\", \"preferences\")\n",
    "memories = store.search(namespace, query=\"What does the user like to eat?\", limit=3)\n",
    "\n",
    "for m in memories:\n",
    "    print(f\"{m.key}: {m.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}