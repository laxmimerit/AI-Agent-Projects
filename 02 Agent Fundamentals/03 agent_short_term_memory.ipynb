{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Short-Term Memory\n",
    "\n",
    "Short-term memory stores conversation history within a session using checkpointers.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Checkpointers persist conversation history\n",
    "- SQLite for development, PostgreSQL for production\n",
    "- Thread IDs manage separate sessions\n",
    "- Access agent state in tools with ToolRuntime\n",
    "- Modify agent state from tools for context offloading\n",
    "- Save/load conversation summaries for long conversations\n",
    "\n",
    "## Checkpointer Comparison\n",
    "\n",
    "| Type | Use Case | Setup |\n",
    "|------|----------|-------|\n",
    "| **SQLite** | Development, testing | Simple file-based |\n",
    "| **PostgreSQL** | Production, multi-user | Database connection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "from scripts import base_tools\n",
    "\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with memory.\n",
    "- Remember previous messages in the conversation\n",
    "- Use conversation history when answering questions\n",
    "- Be concise and accurate\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Problem: No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='9b296f74-456f-424c-9da6-dd25a9a1650d'),\n",
       "  AIMessage(content=\"I don't know your name. You haven't told me yet!\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb809-fa04-7243-a3e7-8d484255bc4b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 37, 'output_tokens': 85, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 69}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(model=model, system_prompt=system_prompt)\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is Laxmi Kant\")]})\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Short-Term Memory: SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "os.makedirs(\"db\", exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(\"db/checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "checkpointer.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=checkpointer,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is Laxmi Kant', additional_kwargs={}, response_metadata={}, id='f145ba2b-9597-4b9e-b631-8832e3efb1d2'),\n",
       "  AIMessage(content='Hello Laxmi Kant! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb805-db78-73e0-8ea4-4a6320b5f569-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 238, 'output_tokens': 12, 'total_tokens': 250, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='796b91b6-3190-42fa-a89a-ccd91311b10f'),\n",
       "  AIMessage(content='Your name is Laxmi Kant.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb805-e018-79d3-8bcd-1569560e921e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 258, 'output_tokens': 7, 'total_tokens': 265, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='My name is Laxmi Kant', additional_kwargs={}, response_metadata={}, id='e47c3b62-e2a8-41fb-9b06-8cfe6be2fdf6'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Okay, Laxmi Kant. How can I help you today?', 'extras': {'signature': 'Cu4BAXLI2nxxNBrjZGAgcUUZQ++uAi2/dANo11+VR7mDh9PiHZNuhAz6h9xEcm2Y0lV34FddPyf51WtBvZIWAn/YbtTGXo+RYXbskODZJQoV26m1wcwube5niYHV+k35cpKQvL9N8Jv1avTL//p8oc13qNcMcCRMMl0RgV2N/JgLpl6x+sq712IYZsdKYBpmcBKudvXzyox84veWPeClgG5y5Lo6/MHHJMQw6YPTmLJfp6ewxTY8gu2t3taQFFsjQY1DVXVi3Dz5VH2pPY43UY/EPdATt8STgex/Q6aI1DTs7mor2xE0bfaj2M6/o0YqqA=='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb809-fee4-7f71-9cba-c1154e9b0128-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 273, 'output_tokens': 57, 'total_tokens': 330, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 44}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='df23ddd6-c5c2-400b-bd43-3989b80855c8'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is Laxmi Kant.', 'extras': {'signature': 'Co8BAXLI2nzhFU3PE4MPJfyCa/7Q7mn+wRnLfB421aZhMYFZk4YBrD1W070cuSjfBNAi/ZFnMo9U5NgsEoXhU4helqXVLLLGSnli9ENL8+FiKfw/dieFXI46v2AgHnqBjZv7J3Y+NtbpKgPEs7ZD9V/MEY9aXD4PJv85XANIvDm5PYl++ckLKyhE95lIZdu38+I='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-045f-7ca3-99b7-d7e5763a9e60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 294, 'output_tokens': 32, 'total_tokens': 326, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 25}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [HumanMessage(\"My name is Laxmi Kant\")]}, config)\n",
    "response = agent.invoke({\"messages\": [HumanMessage(\"What's my name?\")]}, config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20992531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is Laxmi Kant', additional_kwargs={}, response_metadata={}, id='f145ba2b-9597-4b9e-b631-8832e3efb1d2'),\n",
       "  AIMessage(content='Hello Laxmi Kant! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb805-db78-73e0-8ea4-4a6320b5f569-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 238, 'output_tokens': 12, 'total_tokens': 250, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='796b91b6-3190-42fa-a89a-ccd91311b10f'),\n",
       "  AIMessage(content='Your name is Laxmi Kant.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb805-e018-79d3-8bcd-1569560e921e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 258, 'output_tokens': 7, 'total_tokens': 265, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='My name is Laxmi Kant', additional_kwargs={}, response_metadata={}, id='e47c3b62-e2a8-41fb-9b06-8cfe6be2fdf6'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Okay, Laxmi Kant. How can I help you today?', 'extras': {'signature': 'Cu4BAXLI2nxxNBrjZGAgcUUZQ++uAi2/dANo11+VR7mDh9PiHZNuhAz6h9xEcm2Y0lV34FddPyf51WtBvZIWAn/YbtTGXo+RYXbskODZJQoV26m1wcwube5niYHV+k35cpKQvL9N8Jv1avTL//p8oc13qNcMcCRMMl0RgV2N/JgLpl6x+sq712IYZsdKYBpmcBKudvXzyox84veWPeClgG5y5Lo6/MHHJMQw6YPTmLJfp6ewxTY8gu2t3taQFFsjQY1DVXVi3Dz5VH2pPY43UY/EPdATt8STgex/Q6aI1DTs7mor2xE0bfaj2M6/o0YqqA=='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb809-fee4-7f71-9cba-c1154e9b0128-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 273, 'output_tokens': 57, 'total_tokens': 330, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 44}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='df23ddd6-c5c2-400b-bd43-3989b80855c8'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is Laxmi Kant.', 'extras': {'signature': 'Co8BAXLI2nzhFU3PE4MPJfyCa/7Q7mn+wRnLfB421aZhMYFZk4YBrD1W070cuSjfBNAi/ZFnMo9U5NgsEoXhU4helqXVLLLGSnli9ENL8+FiKfw/dieFXI46v2AgHnqBjZv7J3Y+NtbpKgPEs7ZD9V/MEY9aXD4PJv85XANIvDm5PYl++ckLKyhE95lIZdu38+I='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-045f-7ca3-99b7-d7e5763a9e60-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 294, 'output_tokens': 32, 'total_tokens': 326, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 25}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Short-Term Memory: PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your city is Mumbai.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "pg_conn = psycopg.connect(os.getenv(\"POSTGRESQL_URL\"), autocommit=True)\n",
    "pg_checkpointer = PostgresSaver(pg_conn)\n",
    "pg_checkpointer.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=pg_checkpointer,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"postgres_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [HumanMessage(\"My city is Mumbai\")]}, config)\n",
    "response = agent.invoke({\"messages\": [HumanMessage(\"What's my city?\")]}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Context Offloading: Read State in Tools\n",
    "\n",
    "Access agent state to save conversation summaries for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# context is immutable\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "    session_id: str\n",
    "\n",
    "@tool\n",
    "def save_conversation_summary(summary: str, runtime: ToolRuntime):\n",
    "    \"\"\"Save conversation summary to disk for context offloading.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    thread_id = runtime.context.thread_id\n",
    "    \n",
    "    # Create directory structure\n",
    "    summary_dir = Path(f\"data/{user_id}/{thread_id}\")\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write summary\n",
    "    summary_path = summary_dir / \"summary.md\"\n",
    "    summary_path.write_text(summary)\n",
    "    \n",
    "    return f\"Summary saved to {summary_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have saved the summary of our conversation.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test save summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=UserContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session_1\"}}\n",
    "user_context = UserContext(user_id='kgptalkie', session_id='session_1')\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save this summary: User discussed Python and AI topics\")]\n",
    "}, config=config, context=user_context)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Context Offloading: Modify State in Tools\n",
    "\n",
    "Load previous summaries and inject them into agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def load_conversation_summary(runtime: ToolRuntime):\n",
    "    \"\"\"Load previous conversation summary from disk.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    # thread_id = runtime.context.thread_id\n",
    "    thread_id = runtime.config['configurable']['thread_id']\n",
    "    \n",
    "    summary_path = Path(f\"data/{user_id}/{thread_id}/summary.md\")\n",
    "    \n",
    "    if not summary_path.exists():\n",
    "        return Command(update={\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    \"No previous summary found.\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Read summary\n",
    "    summary_text = summary_path.read_text()\n",
    "    \n",
    "    # Update state with summary as system message\n",
    "    return Command(update={\n",
    "        \"messages\": [\n",
    "            SystemMessage(f\"Previous conversation summary:\\n{summary_text}\"),\n",
    "            ToolMessage(\n",
    "                \"Successfully loaded previous summary.\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=UserContext\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Load my previous conversation summary\")]\n",
    "}, config=config, context=user_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfd5b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='55944055-3c8e-4800-9473-9fc5c9ff7d61'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'a3d81d05-605f-47e7-a5e1-a3a6c363ce00': 'CqkCAXLI2nyIaVdC0uFphiF6IaRSAzkKHz2ffHXDdxm1ahOYK2NBBm4KdwHanHq/sBr78FSivq7Ki67tfGiMhzzSyc039FZtvIut6bOD1McYw457m27yMPID47UyEa4NsiMACCPS2YZcnTOisYUIZidGbium5pyMLieBkehAM0Ust7WNvRN0bk2f+JECFNuWYxTVW3ehU7OV/S8uM7so2a5LjijuFC9UEX2+komNo09xZyW8xscp3r/Vs2AnK5gQ0vmzuEcSLG1Cd4pU0kbSiEIvwQSBS6V7+rojxhu26S1abdLiuV4ssXZWq7dfnFWpu1PhCN/Yv8lHBwBJJYN6czDPgSLos2GNCtxqgkV6D8Kp9kpmahAm2TIaHzwH6CFu/W5HjQS7i926rcoK'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb805-ff49-7580-91e3-d606fc29088d-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'a3d81d05-605f-47e7-a5e1-a3a6c363ce00', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 55, 'output_tokens': 77, 'total_tokens': 132, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 55}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='c57e6b40-8ca0-4ffc-9656-f461128865a3', tool_call_id='a3d81d05-605f-47e7-a5e1-a3a6c363ce00'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb806-0462-7713-8ae5-ff8f4f313f4b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 110, 'output_tokens': 9, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='c975087b-ba41-490a-a70d-f0c64f36d095'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'789571df-1732-44ca-a127-6ef51809cb5c': 'CucBAXLI2nwGjfsXC7tD9RBSCida9ziB5NHLltqCQCC/nCrGYWwOlA775S3HffcVRHh/eYTSZlagN0mqsPG+9qYFo4Gchcoe6Ub9so+b5AItJUSx/rx9zuKmiN2IMBl9z/QlpAKe9rrzyN4cFvjWeGFLKzwmWkZaTPmBQuSiAUF2UZCL8lL44CAJN7sv6whkhsEIh7PG/Dr/OpvH/fh6L98yCtN14RJCjZmpKf0r1zbEecICvffxZHKVPGfW6Rg4oGYSZdOi58PvVWufuKBN0pLpuLyy4WMiI11Y2aeD+JzJroqX9opS/T6K'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb806-081e-7900-bbb5-243413e2272b-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': '789571df-1732-44ca-a127-6ef51809cb5c', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 112, 'output_tokens': 52, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 40}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='e24ca0b6-58d9-4fe8-b2a4-0151ea768260'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='55ef587c-9d84-41ce-9480-1590ee3b45bd', tool_call_id='789571df-1732-44ca-a127-6ef51809cb5c'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It says: \"User discussed Python and AI topics\".', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb806-0d25-7e83-8d0a-5092f93ca460-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 19, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='edfe66e5-02a8-4ee8-8275-f3803250923e'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'738ae66c-09f9-4fa1-abad-0dbeca1794b7': 'CvgCAXLI2nw0a89SEpiwwj+08p8+xYY3m++XZ9ZL8eyZ1rT4RaAGsrDqsaWcKAmpsLGYj3v9uLza961lOZAk5LhIXrXC2M2lk4MjXH6ZUOHyOgJoRlHNs390dBDwmFVMdj5F+W2zSYtxjk+TrrXQ7M8bgzUTSKspgTdMZyOnMNYLcmVSiSPnv7358ekyy7ommB3uFH3iGBHA7iuOLeUAO+hClUtuKPL/d4JcoQ57gkULoO/KqcOMU3rxY5trlloWmT9QX3uiekb1NkRzZveEiA2PG79uXhAlRXkcAETmVaHF0YPWW4LPgFc67cKvLPQQAdIniUzKuYiwOsqPAiKoW1pEcRbg+4HBQUQJab2RmXj8hhwuOFTUHfMtVFtMVv4XdQrc8Zx1GwCRb6nosrmYCqOKSV2WNd5hKxanbEnnSvMjMG4vVoU8jyFhjpFDuoHtZ+KvoXdfTDUjt54XUwYO7MUVgmZFl2ydrURcng9BcyRO0Rxctm0t15Ja9A=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-234d-7321-b879-1727d36f78b4-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': '738ae66c-09f9-4fa1-abad-0dbeca1794b7', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 190, 'output_tokens': 100, 'total_tokens': 290, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 78}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='b9d437b0-9886-4ab7-b696-7c797bdc1c89', tool_call_id='738ae66c-09f9-4fa1-abad-0dbeca1794b7'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-2914-7fb3-93d0-1f53a932cf93-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 245, 'output_tokens': 9, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='a2a05d4a-1c5e-4db2-9683-cc3421205a1d'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'f34874bd-fc63-4a10-827a-7e48645981a0': 'Ct0BAXLI2nxr7D77CD79F1yLTU2JxZCHAo5Plkd4ATSMc53N0QNXaZJY4B9lp+kkq7V2R4KR551b0LExBILd9oPxdSsgocXz3IO35p4VQRlyvJet1wl/xVAJwrDf4B1O8pOpNwLZfH9jZOEDukXVAy3vI5Toa+wMEpt6rbIiaNFn6SR8YBHK0G7cn8w6980iUAB6BAGl8/UC+KWTC3S3EmtypRWARh09Ek1Uc+yMU7+m/rqE/UrdJu/XxLQ2Y8uvNdx7mgnV5eLmmDnvEOGi6kITPqUcQgTPYbhHQeY/3ck='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-33db-7670-b807-089e883a0261-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': 'f34874bd-fc63-4a10-827a-7e48645981a0', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 247, 'output_tokens': 51, 'total_tokens': 298, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 39}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='9d4ec8c2-92c3-47fa-bb6f-a2faaf5fd697'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='bbd58a6e-f764-47a1-86d0-afbed3062ad5', tool_call_id='f34874bd-fc63-4a10-827a-7e48645981a0'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It says: \"User discussed Python and AI topics\".', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb80a-3883-7a20-9adc-c9308befc07d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 280, 'output_tokens': 19, 'total_tokens': 299, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Combined: Save and Load Context\n",
    "\n",
    "Real-world example combining both tools for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved for project_alpha\n"
     ]
    }
   ],
   "source": [
    "# Agent with both save and load\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary, load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=UserContext\n",
    ")\n",
    "\n",
    "# Session 2: Have conversation and save summary\n",
    "config = {\"configurable\": {\"thread_id\": \"session_2\"}}\n",
    "user_context = UserContext(user_id='kgptalkie', session_id='session_2')\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"We're building a chatbot using LangChain\")]\n",
    "}, config=config, context=user_context)\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save summary: Building LangChain chatbot with memory and tools\")]\n",
    "}, config=config, context=user_context)\n",
    "\n",
    "print(\"Summary saved for project_alpha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
