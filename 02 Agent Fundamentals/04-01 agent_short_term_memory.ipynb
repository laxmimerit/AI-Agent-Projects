{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Short-Term Memory\n",
    "\n",
    "Short-term memory stores conversation history within a session using checkpointers.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Checkpointers persist conversation history\n",
    "- SQLite for development, PostgreSQL for production\n",
    "- Thread IDs manage separate sessions\n",
    "- Access agent state in tools with ToolRuntime\n",
    "- Modify agent state from tools for context offloading\n",
    "- Save/load conversation summaries for long conversations\n",
    "\n",
    "## Checkpointer Comparison\n",
    "\n",
    "| Type | Use Case | Setup |\n",
    "|------|----------|-------|\n",
    "| **SQLite** | Development, testing | Simple file-based |\n",
    "| **PostgreSQL** | Production, multi-user | Database connection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from langgraph.types import Command\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with memory.\n",
    "- Remember previous messages in the conversation\n",
    "- Use conversation history when answering questions\n",
    "- Be concise and accurate\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Problem: No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a3c26391-f5a0-419c-81c9-c97f4eb5f4d1'),\n",
       "  AIMessage(content=\"I do not know your name. As an AI, I don't have access to personal information about you.\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-18b5-7023-8358-a0c9a37f4db6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 7, 'output_tokens': 227, 'total_tokens': 234, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 204}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(model=model)\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is John\")]})\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Short-Term Memory: SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "os.makedirs(\"db\", exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(\"db/checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "checkpointer.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=checkpointer,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='1b83b791-9bd6-4d99-a6f5-5422afea342a'),\n",
       "  AIMessage(content='Hello John! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-6ee9-7f52-8fce-a760b242659d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 236, 'output_tokens': 10, 'total_tokens': 246, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a423a099-597c-4d00-8104-2235aa93d7df'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is John.', 'extras': {'signature': 'Cr8BAXLI2nxqrhibbTHVglMpNh2Ix8fXHOS+sxUaPnmyI1pzXWhYiUS0+gmvyztpdqslCfHtXZ98stvY1ENrCLI8x5b7f6kHXoH+q4ncb6GkB2MmgfdDJGlkbj5WQDxD4i7LPD1vEBGoAARlGHmMfUFBdMEcENisxkFTV15GuV7YNSdhciRX767L4TVt9BOrtPalBGQ7o5TjETwuIfb7gUvicUaTGdu3jCT8NORK9GeMnD94WlupNS69WCn2y72EWLA='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-731b-7f73-8ac7-461008e7498b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 254, 'output_tokens': 36, 'total_tokens': 290, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}}),\n",
       "  HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='7718d93e-8054-4528-9e81-df2c0079b880'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Okay, John. How can I help you?', 'extras': {'signature': 'CtgBAXLI2nxYKzEHiY96A6mdfwosH6LE6VgaUXD7RZMZGk/ufiP4UYAxZWFduqvaTPSHX3AsHujLw6qW6nK/WyOQkugUxhwxG4w+w6FV23WiIKuunzde9K0TrqKsUtu0fURPc+YelUpkZ6LfxxwxuCpv1lWN0VYGgVAxmQQm/GJdeaV6Vy599b52kTNsJsmGOolpGvY5rfaPkV/7EbgllgfQQinzK2waTOtogR0/7gn6xyzdkcVfuMGGzeftgr2S0Ic5Zo8NS4sxDm/h4WleHMqQY5jSdwbdLUNO'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-21a5-7090-80da-7ec0301481a0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 265, 'output_tokens': 46, 'total_tokens': 311, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 36}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='c3411d7b-b9c3-4475-ae06-f41e24adcb94'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is John.', 'extras': {'signature': 'CtEBAXLI2nxsrxz5UvOJNUHCe2fb0/r948PZj7kpzOBfHxINUMpNQDp0eamLbxyN5YCZ+tw7KeoVPim45mdUZk9T4ijCE1mOsmLVIPchTYRvN3+jFg7XSJtf9brMh6ryE0vZk2sCWHHQpPZ/2T+GDHasRxcWzYqa0Z3rlMF0FxNOe3BxFrgVrq3l9eByKrjcr9EoQqoOFX22GCV6HrbB5P8HgaNrbiOm2KaWatSc3HpQt6m9ehiI71YXrN4Hu+kTmrtRYMHLrEYiMB3LVYJSuP8WR4c='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-264a-7e00-b6d9-8d033d5ec01f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 283, 'output_tokens': 40, 'total_tokens': 323, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 35}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [HumanMessage(\"My name is John\")]}, config)\n",
    "response = agent.invoke({\"messages\": [HumanMessage(\"What's my name?\")]}, config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20992531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='1b83b791-9bd6-4d99-a6f5-5422afea342a'),\n",
       "  AIMessage(content='Hello John! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-6ee9-7f52-8fce-a760b242659d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 236, 'output_tokens': 10, 'total_tokens': 246, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a423a099-597c-4d00-8104-2235aa93d7df'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is John.', 'extras': {'signature': 'Cr8BAXLI2nxqrhibbTHVglMpNh2Ix8fXHOS+sxUaPnmyI1pzXWhYiUS0+gmvyztpdqslCfHtXZ98stvY1ENrCLI8x5b7f6kHXoH+q4ncb6GkB2MmgfdDJGlkbj5WQDxD4i7LPD1vEBGoAARlGHmMfUFBdMEcENisxkFTV15GuV7YNSdhciRX767L4TVt9BOrtPalBGQ7o5TjETwuIfb7gUvicUaTGdu3jCT8NORK9GeMnD94WlupNS69WCn2y72EWLA='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-731b-7f73-8ac7-461008e7498b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 254, 'output_tokens': 36, 'total_tokens': 290, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}}),\n",
       "  HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='7718d93e-8054-4528-9e81-df2c0079b880'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Okay, John. How can I help you?', 'extras': {'signature': 'CtgBAXLI2nxYKzEHiY96A6mdfwosH6LE6VgaUXD7RZMZGk/ufiP4UYAxZWFduqvaTPSHX3AsHujLw6qW6nK/WyOQkugUxhwxG4w+w6FV23WiIKuunzde9K0TrqKsUtu0fURPc+YelUpkZ6LfxxwxuCpv1lWN0VYGgVAxmQQm/GJdeaV6Vy599b52kTNsJsmGOolpGvY5rfaPkV/7EbgllgfQQinzK2waTOtogR0/7gn6xyzdkcVfuMGGzeftgr2S0Ic5Zo8NS4sxDm/h4WleHMqQY5jSdwbdLUNO'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-21a5-7090-80da-7ec0301481a0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 265, 'output_tokens': 46, 'total_tokens': 311, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 36}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='c3411d7b-b9c3-4475-ae06-f41e24adcb94'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is John.', 'extras': {'signature': 'CtEBAXLI2nxsrxz5UvOJNUHCe2fb0/r948PZj7kpzOBfHxINUMpNQDp0eamLbxyN5YCZ+tw7KeoVPim45mdUZk9T4ijCE1mOsmLVIPchTYRvN3+jFg7XSJtf9brMh6ryE0vZk2sCWHHQpPZ/2T+GDHasRxcWzYqa0Z3rlMF0FxNOe3BxFrgVrq3l9eByKrjcr9EoQqoOFX22GCV6HrbB5P8HgaNrbiOm2KaWatSc3HpQt6m9ehiI71YXrN4Hu+kTmrtRYMHLrEYiMB3LVYJSuP8WR4c='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-264a-7e00-b6d9-8d033d5ec01f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 283, 'output_tokens': 40, 'total_tokens': 323, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 35}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Short-Term Memory: PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your city is Mumbai.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "pg_conn = psycopg.connect(os.getenv(\"POSTGRESQL_URL\"), autocommit=True)\n",
    "pg_checkpointer = PostgresSaver(pg_conn)\n",
    "pg_checkpointer.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=pg_checkpointer,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"postgres_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [HumanMessage(\"My city is Mumbai\")]}, config)\n",
    "response = agent.invoke({\"messages\": [HumanMessage(\"What's my city?\")]}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Context Offloading: Read State in Tools\n",
    "\n",
    "Access agent state to save conversation summaries for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "class CustomContext(BaseModel):\n    user_id: str\n    thread_id: str\n\n@tool\ndef save_conversation_summary(summary: str, runtime: ToolRuntime[CustomContext]):\n    \"\"\"Save conversation summary to disk for context offloading.\"\"\"\n    user_id = runtime.context.user_id\n    thread_id = runtime.context.thread_id\n    \n    # Create directory structure\n    summary_dir = Path(f\"data/{user_id}/{thread_id}\")\n    summary_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Write summary\n    summary_path = summary_dir / \"summary.md\"\n    summary_path.write_text(summary)\n    \n    return f\"Summary saved to {summary_path}\""
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have saved the summary of our conversation.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test save summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save this summary: User discussed Python and AI topics\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Context Offloading: Modify State in Tools\n",
    "\n",
    "Load previous summaries and inject them into agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "@tool\ndef load_conversation_summary(runtime: ToolRuntime[CustomContext]):\n    \"\"\"Load previous conversation summary from disk.\"\"\"\n    user_id = runtime.context.user_id\n    thread_id = runtime.context.thread_id\n    \n    summary_path = Path(f\"data/{user_id}/{thread_id}/summary.md\")\n    \n    if not summary_path.exists():\n        return Command(update={\n            \"messages\": [\n                ToolMessage(\n                    \"No previous summary found.\",\n                    tool_call_id=runtime.tool_call_id\n                )\n            ]\n        })\n    \n    # Read summary\n    summary_text = summary_path.read_text()\n    \n    # Update state with summary as system message\n    return Command(update={\n        \"messages\": [\n            SystemMessage(f\"Previous conversation summary:\\n{summary_text}\"),\n            ToolMessage(\n                \"Successfully loaded previous summary.\",\n                tool_call_id=runtime.tool_call_id\n            )\n        ]\n    })"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Load my previous conversation summary\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfd5b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='1ee26e6d-b8b0-4ce3-bc94-f65e61ba9472'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'b4d1620d-9795-4ebd-bff1-496763b651e4': 'CpQCAXLI2nyHVcIWe/V9eAxm5z/TcRlBY+tyRIZBCMZlesn1NYXHj1R6a9TXUzHPZ9Gzxp1SqfaYJtLiPeQN8Yqj2fvnScfUK9F6pzNlwd1KmJYQdpEa5slHO/cKznwPhrTVGM00REyaGrzTz/3qR2ufCWkoNXByQoAK5InSMnfnXTAGJOBzfdxY/v1DK9otZmJburOsFEHuE0ZNqPPaWiPhiCsrm9f1FGtUHrB5rHb7FKfHZ5HEG+euGfsOISR6I7dkMohWqFVD21TgWhZYyZFsNMOSvuPbHx/+kBv5PsJZCaaBNpThEwo1BJ/G9Ew/dwzzEBw0PMXCfK7GrHx8h8xGUAbU2oNdGkH62o2mdPk2dGO87X+F'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-da1f-7812-9042-85ad0ffa3156-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'b4d1620d-9795-4ebd-bff1-496763b651e4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 55, 'output_tokens': 72, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 50}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='faafcb40-8882-4721-955e-86350e3322d0', tool_call_id='b4d1620d-9795-4ebd-bff1-496763b651e4'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-df2d-7303-9158-a8b2d27f08f7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 110, 'output_tokens': 9, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='6921842b-41aa-42d4-b5d1-1095a16059e4'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'f9d3a596-3ca2-4f0f-830f-d5fe177322c8': 'CsIBAXLI2nxIgGejOG0JM1c0JOYfG3bYcQUxgjYmxvaGs/2xmP/dT5koKgI89aY5gxsjX8tVhyZ+qx9SuqbDmHljn3Y36KUKqxd8QjnaykVFEjMRegai8fXoJdeONgSxOTBsBeJR8WVESNSD1Wbc1h3Zi8djr+tPoAMgOUXs4XVKB91M+VzCbB+qRZ62amv48a6t4MavpxK2xiBalJxmYruMFsYr3n5NoyUeL6A+cByuMqwCuWLnIie6pfmdzjBbzfgqPPQ='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-e834-7d41-aaa2-2885f539f112-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': 'f9d3a596-3ca2-4f0f-830f-d5fe177322c8', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 112, 'output_tokens': 45, 'total_tokens': 157, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 33}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='dfdb804b-ad87-4618-95bd-ffa880d3ad2d'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='32556847-65c9-4984-85b0-d3b50ba9e950', tool_call_id='f9d3a596-3ca2-4f0f-830f-d5fe177322c8'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It states: \"User discussed Python and AI topics\".', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-eccd-7c00-8937-2a9d53ff32fc-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 19, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='4762b68f-5f91-43a8-a8c3-fcd6c7a28a34'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'ed3b3923-676f-4c97-abce-8657bb93c279': 'Ct0CAXLI2nyuqnhy3+JbhrewlXsL0yRuwEwnN6izKdDha4tVSxNgJfbXwg67ckYgBJfwxl/xKjrVQIxJ/Em8G3wlczKLTj0LXXHZo3dI04O1GNEVz4YXsyp4QMa8pZEK/0wGc+kLfZqCeEeI6BykL2bZF2y+siK/ql1wrY9zNuq6UJG0yoHe9nd0cc7luhN6ino6TBjEHNe/aFpiflDW0ijDAR2kP132fUefOAQtTvuC/DwxydL+A23k8/1Qw7JF7v/1dtYjD9OfigizzjZBkrbMppQnoLia83L8lbTDHzF0fXNFcl0xmjSkQKqdVLS8erLpCFD+Oqp8KpmtiiGhevqwBPEEHBW9CGwv6QPYRPTPnHr8/qim4nf58J5DTrBbbItphppHeUGkoHUTQQYlJUnIeydIQFbmDWmnlXFRJ4djarZjD3fSo3yq1PqgyMGePzSbUBasiandMo1gVrEJvA=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-5cf4-77a1-ba4c-8bcf9026ab9b-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'ed3b3923-676f-4c97-abce-8657bb93c279', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 190, 'output_tokens': 88, 'total_tokens': 278, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 66}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='aea4057e-318d-4c1d-8516-11d2d33f1243', tool_call_id='ed3b3923-676f-4c97-abce-8657bb93c279'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-62e2-7ea0-847d-a70b23640d64-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 245, 'output_tokens': 9, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='10373e99-fdc7-4c80-a00e-5183bfa8e06c'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'e5a30d91-8b03-4704-a8d1-3ef6b3296cc3': 'CrkBAXLI2nxr9kyHK++gYPAXcvfXY8xwizQudxyhJeepoKnDQ22C9zXGZBzIK5CW6Q34rGUgdYTj7/TKS22AAB0j83c/GBirEabKZ0RxWlK6eucyCZMfb5GM41hByfZa7GB5jGyHUyb46aqfkpyvQjx/X9gW0fTnaTFyxWFFur0/WIkn4ZEwAJ4mwRz/inq526kLYYQW/FC6nOYQC0HzHiB58QFc4G/4wwgdYr451Suxdqf8Zg6h4KcSlkM='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-673e-7810-88ad-452cdb332bdf-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': 'e5a30d91-8b03-4704-a8d1-3ef6b3296cc3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 247, 'output_tokens': 43, 'total_tokens': 290, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='6918709a-8391-478e-8a8c-b7450ac93b6b'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='0491feb3-a040-4784-ae97-9aeec4c501b6', tool_call_id='e5a30d91-8b03-4704-a8d1-3ef6b3296cc3'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It states: \"User discussed Python and AI topics\".', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba1bb-6bc5-7831-884a-79161007291a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 280, 'output_tokens': 19, 'total_tokens': 299, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Combined: Save and Load Context\n",
    "\n",
    "Real-world example combining both tools for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved for project_alpha\n"
     ]
    }
   ],
   "source": [
    "# Agent with both save and load\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary, load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "# Session 1: Have conversation and save summary\n",
    "config = {\"configurable\": {\"thread_id\": \"project_alpha\"}}\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"We're building a chatbot using LangChain\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save summary: Building LangChain chatbot with memory and tools\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "print(\"Summary saved for project_alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7c558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}