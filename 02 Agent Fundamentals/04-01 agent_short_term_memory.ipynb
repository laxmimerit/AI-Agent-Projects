{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Short-Term Memory\n",
    "\n",
    "Short-term memory stores conversation history within a session using checkpointers.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Checkpointers persist conversation history\n",
    "- SQLite for development, PostgreSQL for production\n",
    "- Thread IDs manage separate sessions\n",
    "- Access agent state in tools with ToolRuntime\n",
    "- Modify agent state from tools for context offloading\n",
    "- Save/load conversation summaries for long conversations\n",
    "\n",
    "## Checkpointer Comparison\n",
    "\n",
    "| Type | Use Case | Setup |\n",
    "|------|----------|-------|\n",
    "| **SQLite** | Development, testing | Simple file-based |\n",
    "| **PostgreSQL** | Production, multi-user | Database connection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from langgraph.types import Command\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Problem: No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to personal information about you, including your name. I don't know who you are.\\n\\nIf you'd like me to refer to you by a specific name during our conversation, feel free to tell me!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(model=model)\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is John\")]})\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Short-Term Memory: SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "os.makedirs(\"db\", exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(\"db/checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have memory of past conversations. Could you please tell me your name again?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is John\")]}, config)\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]}, config)\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20992531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='41f29461-4ba2-4ec3-8e3d-94a88e10acc1'),\n",
       "  AIMessage(content='Hello John! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba176-c2ad-7450-b4ae-9803ec00dd25-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 206, 'output_tokens': 10, 'total_tokens': 216, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a5896699-f58b-4611-9b78-d155793343e0'),\n",
       "  AIMessage(content=\"I'm sorry, I don't have memory of past conversations. Could you please tell me your name again?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba176-c64b-7123-98b1-708eda3b118d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 224, 'output_tokens': 24, 'total_tokens': 248, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Short-Term Memory: PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.checkpoint.postgres import PostgresSaver\n",
    "# import psycopg\n",
    "\n",
    "# with PostgresSaver.from_conn_string(os.getenv(\"POSTGRESQL_URL\")) as checkpointer:\n",
    "#     agent = create_agent(\n",
    "#         model=model,\n",
    "#         tools=[base_tools.web_search, base_tools.get_weather],\n",
    "#         checkpointer=checkpointer\n",
    "#     )\n",
    "    \n",
    "#     config = {\"configurable\": {\"thread_id\": \"postgres_session\"}}\n",
    "    \n",
    "#     agent.invoke({'messages': [HumanMessage(\"My city is Mumbai\")]}, config)\n",
    "#     response = agent.invoke({'messages': [HumanMessage(\"What's my city?\")]}, config)\n",
    "    \n",
    "#     response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Context Offloading: Read State in Tools\n",
    "\n",
    "Access agent state to save conversation summaries for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "    thread_id: str\n",
    "\n",
    "@tool\n",
    "def save_conversation_summary(summary: str, runtime: ToolRuntime[CustomContext]) -> str:\n",
    "    \"\"\"Save conversation summary to disk for context offloading.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    thread_id = runtime.context.thread_id\n",
    "    \n",
    "    # Create directory structure\n",
    "    summary_dir = Path(f\"data/{user_id}/{thread_id}\")\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write summary\n",
    "    summary_path = summary_dir / \"summary.md\"\n",
    "    summary_path.write_text(summary)\n",
    "    \n",
    "    return f\"Summary saved to {summary_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have saved the summary of our conversation.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test save summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save this summary: User discussed Python and AI topics\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Context Offloading: Modify State in Tools\n",
    "\n",
    "Load previous summaries and inject them into agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def load_conversation_summary(runtime: ToolRuntime[CustomContext]) -> Command:\n",
    "    \"\"\"Load previous conversation summary from disk.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    thread_id = runtime.context.thread_id\n",
    "    \n",
    "    summary_path = Path(f\"data/{user_id}/{thread_id}/summary.md\")\n",
    "    \n",
    "    if not summary_path.exists():\n",
    "        return Command(update={\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    \"No previous summary found.\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Read summary\n",
    "    summary_text = summary_path.read_text()\n",
    "    \n",
    "    # Update state with summary as system message\n",
    "    return Command(update={\n",
    "        \"messages\": [\n",
    "            SystemMessage(f\"Previous conversation summary:\\n{summary_text}\"),\n",
    "            ToolMessage(\n",
    "                \"Successfully loaded previous summary.\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Load my previous conversation summary\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfd5b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='507b082c-6c50-424e-899d-f06385a03cae'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'d0a8af1f-2729-4453-a7f8-45225df71b74': 'CqICAXLI2nyu/aehi5KkIa3OtfkQlp1cgOKbNBGgOLeVVLg+QwQvu02engdoc4LYoIr6yw2qKAhQ6BqyKaxJu9cQIZaOA7PzDRfMILaYeCt8oFthyTRKYNvZNhL9O9s4HmYxZOdFJpJLru977ukSJt+ir/yXSxK1t/Y/ZbuBy+KfnkbRlsacEYaQ2X5bAmNHh3/whw4Ab+U2HdsXyKI0v0Oz9fdHDpffuVFB/kPZliZwNAmYoPyx9QpmBqHdyt55aeLMKjeP6t/ZFK351Nrm6nFG8BEacoQT7jeTafTI9zIYiAK7Ywpk8dGptM/nnCcvXCm3aE5an7dzuLH2z7pwmmNv/CeBw4734RSUgjymiHHgxODgNX2o8nAdCpizPtwpVxUXpXU='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17a-460c-76f1-b88a-a8c73abd46db-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'd0a8af1f-2729-4453-a7f8-45225df71b74', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 55, 'output_tokens': 77, 'total_tokens': 132, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 55}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='c5c31a5f-af63-45da-8112-585b000027e8', tool_call_id='d0a8af1f-2729-4453-a7f8-45225df71b74'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17a-4b57-7972-9bb7-a716445713ae-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 110, 'output_tokens': 9, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='30c98675-b99d-410e-a07f-5823abd25f1f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'ee7ff985-f5e8-4400-9095-f2f293ba4a91': 'Cr4CAXLI2nzdt/vsSJh1B/aFGXS8X2t+TmsqSKE641NM97s1CYHuHZgGt3YdmCvaIbQs5weS1ONr0KGwMVHiDyShm3Uc/gQnBTTbwNVyPC5mgYFaYDUzzTgu2l5G/h63AZUdL/4WmN537FX/5g2rHVjSciMjVVLw9XHKf9UOL6GM5PQpPnMPuVn91QFdphAITARDh/VL0ZD6v31+fJ3PprQME68YUxcj62l3BYZsmDde9bXqR903JrMKbWnTQ0FFj3WfNG5e3V8T0k0B47V5pIHbGL7zncVild6u2b79u8wrAZ/WKj3a9NGBB+wTdyWICoPQ6aHQNnECIVHB+Pk3ZvM3DjmJlLt06GQFEvYgZYfh7jdjCXKljagHCtYR7xlIDzZgeRxkaQbF7GpVdZR2e1UpYojPirtQ4O6wiqo3jHSq'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17a-d9ae-7831-935e-1920f4e99584-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'ee7ff985-f5e8-4400-9095-f2f293ba4a91', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 131, 'output_tokens': 84, 'total_tokens': 215, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 62}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='8d8b9c07-c9df-447a-98ed-11920bf8b33c', tool_call_id='ee7ff985-f5e8-4400-9095-f2f293ba4a91'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17a-df17-7022-80f8-6db59b15b523-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 186, 'output_tokens': 9, 'total_tokens': 195, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='fabad238-f9de-40df-b34f-8d4c05c158a8'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'b2e3c581-2fcd-4670-915b-fe5cb4b1a43b': 'CoUCAXLI2ny/7vG3HM6U2DQuQki2kgMkaW6rufVaA3ubpOBXsvoHt3x9xPP6/yM9Xj2FnPcHZR0QE6ZGpXunUw2mdz47Otd+JoKtR/SqGOyZjLEe7v51yO8AB6TjUaGfwkJM2DIw5N7+vfQ9xDRAAqfej1zlo4Yvl2FOxFe7GdYMqbppjfTqjYWKxY3ZyhKSLQNcwBo5/rmleVQnjEbjIMWv3r07EAdtOCipfmrG2XhP0Vd4yUcooZB5FQGBJ/tozXhRL0edbESHr7OMftr4addVLQkJzMhGcRJneZPIw4Oc2wsyq/RYBS/bC4ibSsjA3dqtJXEtvz8vA83m07ZeHfUr7rGqznIR'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17b-41e5-7643-a124-5a86a9d344d4-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': 'b2e3c581-2fcd-4670-915b-fe5cb4b1a43b', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 188, 'output_tokens': 60, 'total_tokens': 248, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 48}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='1f222131-acbf-4364-9d86-2a454586815f'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='207c0e27-a458-4846-a094-fc6af8b58050', tool_call_id='b2e3c581-2fcd-4670-915b-fe5cb4b1a43b'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It states: \"User discussed Python and AI topics.\"', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba17b-46d5-71d1-b265-48fc2448fa7e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 221, 'output_tokens': 19, 'total_tokens': 240, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Combined: Save and Load Context\n",
    "\n",
    "Real-world example combining both tools for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved for project_alpha\n"
     ]
    }
   ],
   "source": [
    "# Agent with both save and load\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary, load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "# Session 1: Have conversation and save summary\n",
    "config = {\"configurable\": {\"thread_id\": \"project_alpha\"}}\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"We're building a chatbot using LangChain\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save summary: Building LangChain chatbot with memory and tools\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "print(\"Summary saved for project_alpha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
