{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Short-Term Memory\n",
    "\n",
    "Short-term memory stores conversation history within a session using checkpointers.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Checkpointers persist conversation history\n",
    "- SQLite for development, PostgreSQL for production\n",
    "- Thread IDs manage separate sessions\n",
    "- Access agent state in tools with ToolRuntime\n",
    "- Modify agent state from tools for context offloading\n",
    "- Save/load conversation summaries for long conversations\n",
    "\n",
    "## Checkpointer Comparison\n",
    "\n",
    "| Type | Use Case | Setup |\n",
    "|------|----------|-------|\n",
    "| **SQLite** | Development, testing | Simple file-based |\n",
    "| **PostgreSQL** | Production, multi-user | Database connection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from langgraph.types import Command\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with memory.\n",
    "- Remember previous messages in the conversation\n",
    "- Use conversation history when answering questions\n",
    "- Be concise and accurate\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Problem: No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='d9806100-b985-43f4-94a2-322f9fcf67a7'),\n",
       "  AIMessage(content=\"I don't know your name. As an AI, I don't have access to personal information about you or a memory of who you are from past interactions.\\n\\nIf you'd like me to know your name for our current conversation, you're welcome to tell me!\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-3665-7f31-8b22-4bcb08d73614-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 7, 'output_tokens': 514, 'total_tokens': 521, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 456}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(model=model)\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is John\")]})\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Short-Term Memory: SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "os.makedirs(\"db\", exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(\"db/checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "checkpointer.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=checkpointer,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='1b83b791-9bd6-4d99-a6f5-5422afea342a'),\n",
       "  AIMessage(content='Hello John! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-6ee9-7f52-8fce-a760b242659d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 236, 'output_tokens': 10, 'total_tokens': 246, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a423a099-597c-4d00-8104-2235aa93d7df'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Your name is John.', 'extras': {'signature': 'Cr8BAXLI2nxqrhibbTHVglMpNh2Ix8fXHOS+sxUaPnmyI1pzXWhYiUS0+gmvyztpdqslCfHtXZ98stvY1ENrCLI8x5b7f6kHXoH+q4ncb6GkB2MmgfdDJGlkbj5WQDxD4i7LPD1vEBGoAARlGHmMfUFBdMEcENisxkFTV15GuV7YNSdhciRX767L4TVt9BOrtPalBGQ7o5TjETwuIfb7gUvicUaTGdu3jCT8NORK9GeMnD94WlupNS69WCn2y72EWLA='}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-731b-7f73-8ac7-461008e7498b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 254, 'output_tokens': 36, 'total_tokens': 290, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [HumanMessage(\"My name is John\")]}, config)\n",
    "response = agent.invoke({\"messages\": [HumanMessage(\"What's my name?\")]}, config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20992531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is John', additional_kwargs={}, response_metadata={}, id='ec1e622c-a5af-4cb3-ba57-eae9e0722177'),\n",
       "  AIMessage(content='Hello John! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba185-d33a-7ab2-ae09-af12af9d9bf9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 206, 'output_tokens': 10, 'total_tokens': 216, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='b94b3ba3-76df-4b54-9993-2833f920e608'),\n",
       "  AIMessage(content=\"I'm sorry, I don't remember your name. Could you please remind me?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba185-d71c-7101-939a-a9dcabaf8dea-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 224, 'output_tokens': 19, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Short-Term Memory: PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57106d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "with PostgresSaver.from_conn_string(os.getenv(\"POSTGRESQL_URL\")) as checkpointer:\n",
    "    agent = create_agent(\n",
    "        model=model,\n",
    "        tools=[base_tools.web_search, base_tools.get_weather],\n",
    "        checkpointer=checkpointer\n",
    "    )\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"postgres_session\"}}\n",
    "    \n",
    "    agent.invoke({'messages': [HumanMessage(\"My city is Mumbai\")]}, config)\n",
    "    response = agent.invoke({'messages': [HumanMessage(\"What's my city?\")]}, config)\n",
    "    \n",
    "    response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Context Offloading: Read State in Tools\n",
    "\n",
    "Access agent state to save conversation summaries for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "    thread_id: str\n",
    "\n",
    "@tool\n",
    "def save_conversation_summary(summary: str, runtime: ToolRuntime[CustomContext]) -> str:\n",
    "    \"\"\"Save conversation summary to disk for context offloading.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    thread_id = runtime.context.thread_id\n",
    "    \n",
    "    # Create directory structure\n",
    "    summary_dir = Path(f\"data/{user_id}/{thread_id}\")\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write summary\n",
    "    summary_path = summary_dir / \"summary.md\"\n",
    "    summary_path.write_text(summary)\n",
    "    \n",
    "    return f\"Summary saved to {summary_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have saved the summary of our conversation.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test save summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save this summary: User discussed Python and AI topics\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Context Offloading: Modify State in Tools\n",
    "\n",
    "Load previous summaries and inject them into agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def load_conversation_summary(runtime: ToolRuntime[CustomContext]) -> Command:\n",
    "    \"\"\"Load previous conversation summary from disk.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    thread_id = runtime.context.thread_id\n",
    "    \n",
    "    summary_path = Path(f\"data/{user_id}/{thread_id}/summary.md\")\n",
    "    \n",
    "    if not summary_path.exists():\n",
    "        return Command(update={\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    \"No previous summary found.\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    # Read summary\n",
    "    summary_text = summary_path.read_text()\n",
    "    \n",
    "    # Update state with summary as system message\n",
    "    return Command(update={\n",
    "        \"messages\": [\n",
    "            SystemMessage(f\"Previous conversation summary:\\n{summary_text}\"),\n",
    "            ToolMessage(\n",
    "                \"Successfully loaded previous summary.\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load summary\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Load my previous conversation summary\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_123\", thread_id=\"session1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd5b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Save this summary: User discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='1ee26e6d-b8b0-4ce3-bc94-f65e61ba9472'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'save_conversation_summary', 'arguments': '{\"summary\": \"User discussed Python and AI topics\"}'}, '__gemini_function_call_thought_signatures__': {'b4d1620d-9795-4ebd-bff1-496763b651e4': 'CpQCAXLI2nyHVcIWe/V9eAxm5z/TcRlBY+tyRIZBCMZlesn1NYXHj1R6a9TXUzHPZ9Gzxp1SqfaYJtLiPeQN8Yqj2fvnScfUK9F6pzNlwd1KmJYQdpEa5slHO/cKznwPhrTVGM00REyaGrzTz/3qR2ufCWkoNXByQoAK5InSMnfnXTAGJOBzfdxY/v1DK9otZmJburOsFEHuE0ZNqPPaWiPhiCsrm9f1FGtUHrB5rHb7FKfHZ5HEG+euGfsOISR6I7dkMohWqFVD21TgWhZYyZFsNMOSvuPbHx/+kBv5PsJZCaaBNpThEwo1BJ/G9Ew/dwzzEBw0PMXCfK7GrHx8h8xGUAbU2oNdGkH62o2mdPk2dGO87X+F'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-da1f-7812-9042-85ad0ffa3156-0', tool_calls=[{'name': 'save_conversation_summary', 'args': {'summary': 'User discussed Python and AI topics'}, 'id': 'b4d1620d-9795-4ebd-bff1-496763b651e4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 55, 'output_tokens': 72, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 50}}),\n",
       "  ToolMessage(content='Summary saved to data\\\\user_123\\\\session1\\\\summary.md', name='save_conversation_summary', id='faafcb40-8882-4721-955e-86350e3322d0', tool_call_id='b4d1620d-9795-4ebd-bff1-496763b651e4'),\n",
       "  AIMessage(content='I have saved the summary of our conversation.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-df2d-7303-9158-a8b2d27f08f7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 110, 'output_tokens': 9, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='Load my previous conversation summary', additional_kwargs={}, response_metadata={}, id='6921842b-41aa-42d4-b5d1-1095a16059e4'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'load_conversation_summary', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'f9d3a596-3ca2-4f0f-830f-d5fe177322c8': 'CsIBAXLI2nxIgGejOG0JM1c0JOYfG3bYcQUxgjYmxvaGs/2xmP/dT5koKgI89aY5gxsjX8tVhyZ+qx9SuqbDmHljn3Y36KUKqxd8QjnaykVFEjMRegai8fXoJdeONgSxOTBsBeJR8WVESNSD1Wbc1h3Zi8djr+tPoAMgOUXs4XVKB91M+VzCbB+qRZ62amv48a6t4MavpxK2xiBalJxmYruMFsYr3n5NoyUeL6A+cByuMqwCuWLnIie6pfmdzjBbzfgqPPQ='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-e834-7d41-aaa2-2885f539f112-0', tool_calls=[{'name': 'load_conversation_summary', 'args': {}, 'id': 'f9d3a596-3ca2-4f0f-830f-d5fe177322c8', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 112, 'output_tokens': 45, 'total_tokens': 157, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 33}}),\n",
       "  SystemMessage(content='Previous conversation summary:\\nUser discussed Python and AI topics', additional_kwargs={}, response_metadata={}, id='dfdb804b-ad87-4618-95bd-ffa880d3ad2d'),\n",
       "  ToolMessage(content='Successfully loaded previous summary.', name='load_conversation_summary', id='32556847-65c9-4984-85b0-d3b50ba9e950', tool_call_id='f9d3a596-3ca2-4f0f-830f-d5fe177322c8'),\n",
       "  AIMessage(content='I have loaded your previous conversation summary. It states: \"User discussed Python and AI topics\".', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019ba188-eccd-7c00-8937-2a9d53ff32fc-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 19, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Combined: Save and Load Context\n",
    "\n",
    "Real-world example combining both tools for context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved for project_alpha\n"
     ]
    }
   ],
   "source": [
    "# Agent with both save and load\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_conversation_summary, load_conversation_summary],\n",
    "    checkpointer=checkpointer,\n",
    "    context_schema=CustomContext\n",
    ")\n",
    "\n",
    "# Session 1: Have conversation and save summary\n",
    "config = {\"configurable\": {\"thread_id\": \"project_alpha\"}}\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"We're building a chatbot using LangChain\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Save summary: Building LangChain chatbot with memory and tools\")]\n",
    "}, config=config, context=CustomContext(user_id=\"user_456\", thread_id=\"project_alpha\"))\n",
    "\n",
    "print(\"Summary saved for project_alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7c558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
