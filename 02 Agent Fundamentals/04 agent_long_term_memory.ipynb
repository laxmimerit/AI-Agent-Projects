{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agent Long-Term Memory\n",
    "\n",
    "Long-term memory persists user facts across sessions using stores with semantic search.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Store persists data across sessions and threads\n",
    "- PostgresStore with embeddings enables semantic search\n",
    "- Tools access store via runtime.store\n",
    "- Context provides user identification\n",
    "- Namespaces organize memories hierarchically\n",
    "- Semantic search finds relevant memories by meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52547b",
   "metadata": {},
   "source": [
    "## Memory Comparison\n",
    "\n",
    "| Type | Storage | Use Case | Persistence |\n",
    "|------|---------|----------|-------------|\n",
    "| **Short-term** | Checkpointer | Conversation history | Session |\n",
    "| **Long-term** | Store | User preferences, facts | Cross-session |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with long-term memory.\n",
    "\n",
    "MEMORY TOOLS USAGE:\n",
    "\n",
    "save_user_memory - Save when user shares NEW information:\n",
    "- Food preferences (diet, likes, dislikes, allergies)\n",
    "- Work information (role, company, interests)  \n",
    "- Hobbies and personal interests\n",
    "- Location and timezone preferences\n",
    "\n",
    "get_user_memory - Retrieve specific category:\n",
    "- When answering questions about past preferences\n",
    "- When user asks \"what do you know about me?\"\n",
    "- When making personalized recommendations\n",
    "\n",
    "web_search - Retrieve Real-time information\n",
    "- When user ask about news or latest update\n",
    "- When user ask about real-time information\n",
    "\n",
    "GUIDELINES:\n",
    "- Always save when user shares personal information\n",
    "- Use stored preferences to personalize responses\n",
    "- Be conversational and natural\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Setup PostgresStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='gemini-embedding-001')\n",
    "\n",
    "def embed(texts: list[str]):\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "pg_conn = psycopg.connect(os.getenv(\"POSTGRESQL_URL\"), autocommit=True, prepare_threshold=0)\n",
    "store = PostgresStore(pg_conn, index={\"embed\": embed, \"dims\": 768})\n",
    "store.setup()\n",
    "\n",
    "# context is immutable\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Memory Tools with ToolRuntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save_user_memory(category: str, information: dict, runtime: ToolRuntime):\n",
    "    \"\"\"Save user preference or information to long-term memory.\n",
    "    \n",
    "    Args:\n",
    "        category: Category of information (e.g., 'food', 'work', 'hobbies', 'location')\n",
    "        information: Dictionary containing the information to save\n",
    "        \n",
    "    Examples:\n",
    "        category='food', information={'diet': 'vegetarian', 'likes': ['pasta', 'pizza']}\n",
    "        category='work', information={'role': 'Data Scientist', 'interests': ['AI', 'ML']}\n",
    "    \"\"\"\n",
    "    store = runtime.store\n",
    "    user_id = runtime.context.user_id\n",
    "    namespace = (user_id, \"preferences\")\n",
    "    \n",
    "    store.put(namespace, category, information)\n",
    "    return f\"Saved {category} preferences for {user_id}\"\n",
    "\n",
    "@tool\n",
    "def get_user_memory(category: str, runtime: ToolRuntime):\n",
    "    \"\"\"Retrieve user preference or information from long-term memory.\n",
    "    \n",
    "    Args:\n",
    "        category: Category of information to retrieve (e.g., 'food', 'work', 'hobbies')\n",
    "        \n",
    "    Returns:\n",
    "        Stored information for the category or \"not found\" message\n",
    "    \"\"\"\n",
    "    store = runtime.store\n",
    "    user_id = runtime.context.user_id\n",
    "    namespace = (user_id, \"preferences\")\n",
    "    \n",
    "    item = store.get(namespace, category)\n",
    "    if item:\n",
    "        return f\"{category}: {item.value}\"\n",
    "    return f\"No '{category}' information found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Agent with Long-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_saver = PostgresSaver(pg_conn)\n",
    "pg_saver.setup()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_user_memory, get_user_memory, base_tools.web_search],\n",
    "    checkpointer=pg_saver,\n",
    "    store=store,\n",
    "    context_schema=UserContext,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Save User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save user information\n",
    "config = {\"configurable\": {\"thread_id\": \"session_1\"}}\n",
    "user_context = UserContext(user_id='kgptalkie')\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"I'm a vegetarian and I love pasta, pizza, and Italian food\")]\n",
    "}, config=config, context=user_context)\n",
    "\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save work information\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"I work as a Data Scientist and I'm interested in AI and machine learning\")]\n",
    "}, config=config, context=user_context)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Retrieve in New Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread - different conversation, but same user\n",
    "new_config = {\"configurable\": {\"thread_id\": \"session_2\"}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"What do you know about my food preferences?\")]\n",
    "}, config=new_config, context=user_context)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for recommendations based on stored preferences\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Can you recommend a restaurant for me? use web search\")]\n",
    "}, config=new_config, context=user_context)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct store access for semantic search\n",
    "namespace = (\"user_123\", \"preferences\")\n",
    "memories = store.search(namespace, query=\"What does the user like to eat?\", limit=3)\n",
    "\n",
    "for m in memories:\n",
    "    print(f\"{m.key}: {m.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd92a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
