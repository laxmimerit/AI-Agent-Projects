{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Fundamentals\n",
    "\n",
    "Learn the core concepts of building AI agents with LangChain.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Agents combine models with reasoning capabilities\n",
    "- System prompts define agent behavior and personality\n",
    "- Model configuration controls response characteristics\n",
    "- Dynamic model selection enables cost optimization\n",
    "- Role-based prompts create specialized agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "An agent combines a language model with tools to create systems that reason, decide, and work towards solutions iteratively.\n",
    "\n",
    "**Core Components:**\n",
    "1. Model/LLM - The reasoning engine\n",
    "2. System Prompt - Instructions guiding behavior  \n",
    "3. Message History - Conversation context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your First Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate responses.\"\n",
    "\n",
    "# Create agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the agent\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"What is machine learning?\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static model with configuration\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model='gemini-2.5-flash',\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "agent = create_agent(model=model)\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Explain neural networks in one sentence\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed system prompt\n",
    "system_prompt = \"\"\"You are a financial analyst specializing in tech stocks.\n",
    "\n",
    "Guidelines:\n",
    "- Provide data-driven analysis\n",
    "- Keep responses concise (2-3 paragraphs max)\n",
    "- Present numbers with proper formatting ($XXX.XX)\n",
    "- Avoid speculation without data\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"What factors affect stock prices?\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role-Based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer support agent (for comparison)\n",
    "support_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"You are a friendly customer support agent.\n",
    "    \n",
    "    - Use simple language (avoid jargon)\n",
    "    - Ask clarifying questions when needed\n",
    "    - Maintain a warm, empathetic tone\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "response = support_agent.invoke({\n",
    "    'messages': [HumanMessage(\"I can't log into my account\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical expert agent (for comparison)\n",
    "tech_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"You are a technical expert.\n",
    "    \n",
    "    - Provide detailed technical responses\n",
    "    - Use precise terminology\n",
    "    - Include code examples when relevant\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "response = tech_agent.invoke({\n",
    "    'messages': [HumanMessage(\"Explain REST API\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "# Define basic and advanced models\n",
    "basic_model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "advanced_model = ChatGoogleGenerativeAI(model='gemini-3-flash-preview')\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler):\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    \n",
    "    if message_count > 10:\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "    \n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[dynamic_model_selection]\n",
    ")\n",
    "\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What is AI?\")]})\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create your own agent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
