{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Agent Prompt and Context Engineering\n\nMaster advanced prompt engineering techniques and context management for optimal agent performance.\n\n**What you'll learn:**\n- System prompts are the most important agent configuration\n- Specificity beats vagueness every time\n- Examples (few-shot) dramatically improve quality\n- Constraints prevent unwanted behavior\n- Context makes responses more relevant\n- Tool guidance improves decision-making\n- Format control ensures consistent outputs\n- Chain-of-thought improves reasoning"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Prompt Engineering Matters\n",
    "\n",
    "The system prompt is the **most important** configuration for agent behavior:\n",
    "- Defines agent role and personality\n",
    "- Guides decision-making and tool selection\n",
    "- Sets response format and style\n",
    "- Establishes boundaries and constraints\n",
    "\n",
    "**Key Principles:**\n",
    "1. **Be specific** - Vague prompts lead to unpredictable behavior\n",
    "2. **Provide examples** - Show the agent what you want\n",
    "3. **Set constraints** - Define what NOT to do\n",
    "4. **Context matters** - Give relevant background information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic vs Detailed Prompts\n",
    "\n",
    "Compare the impact of prompt specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Basic prompt (vague)\nbasic_prompt = \"You are a helpful assistant.\"\n\nagent_a = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=basic_prompt\n)\n\nprint(\"Basic prompt:\", basic_prompt)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Detailed prompt (specific)\ndetailed_prompt = \"\"\"You are a financial analyst specializing in tech stocks.\n\nYour role:\n- Provide data-driven analysis backed by recent information\n- Use web search to find current stock prices and news\n- Compare companies using concrete metrics\n- Keep responses concise (2-3 paragraphs max)\n\nGuidelines:\n- Always cite sources when using web search results\n- Present numbers with proper formatting ($XXX.XX)\n- Highlight key insights with bullet points\n- Avoid speculation without data\n\"\"\"\n\nagent_b = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=detailed_prompt\n)\n\nprint(\"Detailed prompt:\", detailed_prompt)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare responses\nquery = \"Analyze Apple's stock performance\"\n\nprint(\"=\" * 60)\nprint(\"BASIC PROMPT RESPONSE\")\nprint(\"=\" * 60)\nresponse_a = agent_a.invoke({'messages': [HumanMessage(query)]})\nprint(response_a['messages'][-1].text[:300], \"...\\n\")\n\nprint(\"=\" * 60)\nprint(\"DETAILED PROMPT RESPONSE\")\nprint(\"=\" * 60)\nresponse_b = agent_b.invoke({'messages': [HumanMessage(query)]})\nprint(response_b['messages'][-1].text[:300], \"...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Role-Based Prompts\n",
    "\n",
    "Define clear roles to guide agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Customer support role\nsupport_prompt = \"\"\"You are a friendly and patient customer support agent.\n\nYour responsibilities:\n- Help customers troubleshoot issues\n- Provide clear, step-by-step instructions\n- Maintain a warm, empathetic tone\n- Escalate complex issues appropriately\n\nCommunication style:\n- Use simple language (avoid jargon)\n- Ask clarifying questions when needed\n- Confirm understanding before moving on\n- End with \"Is there anything else I can help with?\"\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=support_prompt\n)\n\nresponse = agent.invoke({\n    'messages': [HumanMessage(\"I can't log into my account\")]\n})\n\nprint(response['messages'][-1].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Constraint-Based Prompts\n",
    "\n",
    "Set clear boundaries for agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "constrained_prompt = \"\"\"You are a medical information assistant.\n\nWhat you CAN do:\n- Provide general health information\n- Explain medical terminology\n- Share wellness tips\n- Direct to appropriate resources\n\nWhat you CANNOT do:\n- Diagnose conditions\n- Prescribe medications\n- Replace professional medical advice\n- Give emergency medical guidance\n\nALWAYS include disclaimer: \"This is not medical advice. Consult a healthcare professional.\"\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=constrained_prompt\n)\n\nresponse = agent.invoke({\n    'messages': [HumanMessage(\"What is hypertension?\")]\n})\n\nprint(response['messages'][-1].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Few-Shot Prompting\n",
    "\n",
    "Provide examples to demonstrate desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "few_shot_prompt = \"\"\"You are a product description writer for an e-commerce site.\n\nFormat your responses like these examples:\n\nExample 1:\nProduct: Wireless Mouse\nDescription: Glide through your workday with our ergonomic wireless mouse. \n- 18-month battery life | 6 programmable buttons | Up to 30ft range\nPerfect for: Professionals, gamers, everyday users\n\nExample 2:\nProduct: Running Shoes\nDescription: Hit the pavement in comfort with these lightweight running shoes.\n- Breathable mesh | Cushioned sole | Arch support\nPerfect for: Runners, fitness enthusiasts, active lifestyles\n\nUse this format for all product descriptions.\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=few_shot_prompt\n)\n\nresponse = agent.invoke({\n    'messages': [HumanMessage(\"Write a description for a laptop\")]\n})\n\nprint(response['messages'][-1].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Context-Aware Prompts\n",
    "\n",
    "Incorporate dynamic context into prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from datetime import datetime\n\n# Dynamic context\ncurrent_date = datetime.now().strftime(\"%Y-%m-%d\")\nuser_tier = \"Premium\"\n\ncontext_prompt = f\"\"\"You are a personalized AI assistant.\n\nCurrent Context:\n- Date: {current_date}\n- User Tier: {user_tier}\n- Available Features: Advanced search, Priority support, Custom reports\n\nBehavior:\n- Mention premium features when relevant\n- Prioritize current/recent information\n- Tailor responses to premium tier benefits\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=context_prompt\n)\n\nprint(\"Context-aware prompt created\")\nprint(f\"Date: {current_date}\")\nprint(f\"User Tier: {user_tier}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tool Usage Guidance\n",
    "\n",
    "Explicitly guide when and how to use tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tool_guidance_prompt = \"\"\"You are a research assistant with web search capabilities.\n\nTool Usage Guidelines:\n\nALWAYS use web_search for:\n- Current events and news\n- Stock prices and financial data\n- Recent statistics or numbers\n- Trending topics\n- Product reviews or comparisons\n\nDO NOT use web_search for:\n- General knowledge questions\n- Mathematical calculations\n- Code examples or explanations\n- Historical facts (before 2024)\n\nWhen using web_search:\n1. Formulate a clear, specific query\n2. Cite the source of information\n3. Synthesize multiple results\n4. Verify consistency across sources\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=tool_guidance_prompt\n)\n\nprint(\"Agent with tool usage guidance created\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test tool selection\nprint(\"Test 1: Should use web search\")\nresponse_a = agent.invoke({\n    'messages': [HumanMessage(\"What is the latest Apple stock price?\")]\n})\nprint(response_a['messages'][-1].text[:200], \"...\\n\")\n\nprint(\"Test 2: Should NOT use web search\")\nresponse_b = agent.invoke({\n    'messages': [HumanMessage(\"What is 25 * 4?\")]\n})\nprint(response_b['messages'][-1].text[:200], \"...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Output Format Control\n",
    "\n",
    "Specify exact output structure and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "format_control_prompt = \"\"\"You are a stock analysis agent.\n\nALWAYS format your analysis exactly like this:\n\n## [COMPANY NAME] Analysis\n\n**Current Price:** $XXX.XX\n**Change:** ±X.XX%\n\n### Key Metrics\n• Market Cap: $XXX billion\n• P/E Ratio: XX.X\n• 52-Week Range: $XXX - $XXX\n\n### Summary\n[2-3 sentences about recent performance]\n\n### Recommendation\nBUY | HOLD | SELL\n\nNEVER deviate from this format.\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=format_control_prompt\n)\n\nresponse = agent.invoke({\n    'messages': [HumanMessage(\"Analyze Microsoft stock\")]\n})\n\nprint(response['messages'][-1].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Chain-of-Thought Prompting\n",
    "\n",
    "Encourage step-by-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cot_prompt = \"\"\"You are an analytical problem solver.\n\nFor every query, follow this reasoning process:\n\n1. **Understand**: Restate the question in your own words\n2. **Break Down**: List the steps needed to solve it\n3. **Gather Data**: Use tools to collect necessary information\n4. **Analyze**: Process and interpret the data\n5. **Conclude**: Provide a clear, actionable answer\n\nALWAYS show your reasoning explicitly.\n\nExample format:\nUnderstanding: [restate question]\nSteps: [list approach]\nData: [tool results]\nAnalysis: [interpretation]\nConclusion: [final answer]\n\"\"\"\n\nagent = create_agent(\n    model=model,\n    tools=[base_tools.web_search],\n    system_prompt=cot_prompt\n)\n\nresponse = agent.invoke({\n    'messages': [HumanMessage(\"Should I invest in Apple or Microsoft?\")]\n})\n\nprint(response['messages'][-1].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Prompt Engineering Best Practices\n\n### DO:\n1. **Be Specific**: Define exact behavior and constraints\n2. **Use Examples**: Show, don't just tell\n3. **Set Boundaries**: Clearly state what NOT to do\n4. **Structure Information**: Use sections, bullets, formatting\n5. **Provide Context**: Include relevant background\n6. **Test Iteratively**: Refine based on actual outputs\n7. **Use Templates**: For consistent output formats\n\n### DON'T:\n1. **Be Vague**: \"Be helpful\" is too generic\n2. **Over-complicate**: Keep prompts focused\n3. **Contradict**: Ensure guidelines are consistent\n4. **Assume**: Spell out expected behavior\n5. **Forget Edge Cases**: Address potential issues\n6. **Skip Testing**: Always validate with real queries"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prompt Template Library\n",
    "\n",
    "Reusable templates for common scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "prompt_templates = {\n    \"customer_support\": \"\"\"You are a {company} customer support agent.\n    - Help users with {products}\n    - Escalate to human if: {escalation_criteria}\n    - Tone: {tone}\n    \"\"\",\n    \n    \"data_analyst\": \"\"\"You are a data analyst for {domain}.\n    - Use {tools} to gather data\n    - Focus on {metrics}\n    - Format: {output_format}\n    \"\"\",\n    \n    \"content_creator\": \"\"\"You are a {content_type} creator.\n    - Style: {writing_style}\n    - Target audience: {audience}\n    - Length: {length}\n    - Include: {required_elements}\n    \"\"\",\n    \n    \"code_reviewer\": \"\"\"You are a {language} code reviewer.\n    - Check for: {review_criteria}\n    - Suggest improvements for: {focus_areas}\n    - Format feedback as: {feedback_format}\n    \"\"\"\n}\n\n# Example usage\nsupport_prompt = prompt_templates[\"customer_support\"].format(\n    company=\"KGP Talkie\",\n    products=\"AI Agent courses and training\",\n    escalation_criteria=\"technical bugs, billing disputes\",\n    tone=\"friendly and professional\"\n)\n\nprint(\"Generated prompt:\")\nprint(support_prompt)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. A/B Testing Prompts\n",
    "\n",
    "Compare different prompt strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "prompts_to_test = {\n    \"A - Direct\": \"Analyze tech stocks and provide recommendations.\",\n    \n    \"B - Structured\": \"\"\"You are a financial analyst.\n    - Research current stock prices\n    - Compare key metrics\n    - Provide buy/hold/sell recommendation\n    \"\"\",\n    \n    \"C - Detailed\": \"\"\"You are a senior financial analyst with 10 years experience.\n    \n    Process:\n    1. Gather current stock data via web search\n    2. Analyze metrics: price, P/E ratio, growth\n    3. Compare against sector averages\n    4. Provide clear recommendation with reasoning\n    \n    Format:\n    - Use bullet points for metrics\n    - Bold important numbers\n    - End with clear action item\n    \"\"\"\n}\n\ntest_query = \"Analyze Tesla stock\"\n\nfor name, prompt in prompts_to_test.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"Testing: {name}\")\n    print(f\"{'='*60}\")\n    \n    agent = create_agent(model=model, tools=[base_tools.web_search], system_prompt=prompt)\n    response = agent.invoke({'messages': [HumanMessage(test_query)]})\n    \n    print(response['messages'][-1].text[:200], \"...\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Design a comprehensive system prompt for one of these scenarios:\n",
    "\n",
    "1. **Travel Planning Agent**\n",
    "   - Helps users plan trips\n",
    "   - Searches for flights, hotels, activities\n",
    "   - Considers budget and preferences\n",
    "\n",
    "2. **Code Review Agent**\n",
    "   - Reviews code for bugs and style\n",
    "   - Suggests improvements\n",
    "   - Explains best practices\n",
    "\n",
    "3. **Health & Wellness Coach**\n",
    "   - Provides fitness and nutrition tips\n",
    "   - Sets and tracks goals\n",
    "   - Motivates and encourages\n",
    "\n",
    "Include:\n",
    "- Clear role definition\n",
    "- Tool usage guidelines\n",
    "- Output format specification\n",
    "- Constraints and boundaries\n",
    "- Examples (few-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}