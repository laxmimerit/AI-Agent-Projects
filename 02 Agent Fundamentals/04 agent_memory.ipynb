{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Memory\n",
    "\n",
    "Short-term memory (conversation history) and long-term memory (user facts across sessions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Courses/Udemy/AI Agent Projects')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "from langchain.tools import tool\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_no_memory = create_agent(model=model)\n",
    "\n",
    "agent_no_memory.invoke({'messages': [HumanMessage(\"My name is John\")]})\n",
    "r = agent_no_memory.invoke({'messages': [HumanMessage(\"What's my name?\")]})\n",
    "\n",
    "r['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-Term Memory: SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "os.makedirs(\"db\", exist_ok=True)\n",
    "conn = sqlite3.connect(\"db/checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather],\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"My name is John\")]}, config)\n",
    "r = agent.invoke({'messages': [HumanMessage(\"What's my name?\")]}, config)\n",
    "\n",
    "r['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple sessions\n",
    "session_a = {\"configurable\": {\"thread_id\": \"session_a\"}}\n",
    "session_b = {\"configurable\": {\"thread_id\": \"session_b\"}}\n",
    "\n",
    "agent.invoke({'messages': [HumanMessage(\"I like Python\")]}, session_a)\n",
    "agent.invoke({'messages': [HumanMessage(\"I like JavaScript\")]}, session_b)\n",
    "\n",
    "r_a = agent.invoke({'messages': [HumanMessage(\"What do I like?\")]}, session_a)\n",
    "r_b = agent.invoke({'messages': [HumanMessage(\"What do I like?\")]}, session_b)\n",
    "\n",
    "print(\"A:\", r_a['messages'][-1].text)\n",
    "print(\"B:\", r_b['messages'][-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-Term Memory: PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import psycopg\n",
    "\n",
    "with PostgresSaver.from_conn_string(os.getenv(\"POSTGRESQL_URL\")) as pg_checkpointer:\n",
    "    agent_pg = create_agent(\n",
    "        model=model,\n",
    "        tools=[base_tools.web_search, base_tools.get_weather],\n",
    "        checkpointer=pg_checkpointer\n",
    "    )\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"postgres_session\"}}\n",
    "    \n",
    "    agent_pg.invoke({'messages': [HumanMessage(\"My city is Mumbai\")]}, config)\n",
    "    r = agent_pg.invoke({'messages': [HumanMessage(\"What's my city?\")]}, config)\n",
    "    \n",
    "    r['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Term Memory: PostgresStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
    "\n",
    "def embed(texts: list[str]):\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "pg_conn = psycopg.connect(os.getenv(\"POSTGRESQL_URL\"), autocommit=True, prepare_threshold=0)\n",
    "store = PostgresStore(pg_conn, index={\"embed\": embed, \"dims\": 768})\n",
    "store.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory tools\n",
    "@tool\n",
    "def save_user_memory(user_id: str, category: str, information: dict) -> str:\n",
    "    \"\"\"Save user information to long-term memory.\"\"\"\n",
    "    store.put((user_id, \"preferences\"), category, information)\n",
    "    return \"saved\"\n",
    "\n",
    "@tool\n",
    "def get_user_memory(user_id: str, category: str) -> str:\n",
    "    \"\"\"Retrieve user information from long-term memory.\"\"\"\n",
    "    item = store.get((user_id, \"preferences\"), category)\n",
    "    return str(item.value) if item else \"not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent with long-term memory tools\n",
    "pg_saver = PostgresSaver(pg_conn)\n",
    "pg_saver.setup()\n",
    "\n",
    "agent_ltm = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, save_user_memory, get_user_memory],\n",
    "    checkpointer=pg_saver\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"ltm_session\"}}\n",
    "\n",
    "# Save preferences\n",
    "agent_ltm.invoke({\n",
    "    'messages': [HumanMessage(\"Save: I'm John from NYC, I prefer Python\")]\n",
    "}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve in new session\n",
    "new_config = {\"configurable\": {\"thread_id\": \"new_session\"}}\n",
    "\n",
    "r = agent_ltm.invoke({\n",
    "    'messages': [HumanMessage(\"What do you know about user john?\")]\n",
    "}, new_config)\n",
    "\n",
    "r['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic search\n",
    "memories = store.search((\"john\", \"preferences\"), query=\"programming\", limit=3)\n",
    "\n",
    "for m in memories:\n",
    "    print(f\"{m.key}: {m.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Comparison\n",
    "\n",
    "| Type | Storage | Use Case | Persistence |\n",
    "|------|---------|----------|-------------|\n",
    "| **Short-term** | Checkpointer | Conversation history | Session |\n",
    "| **Long-term** | Store | User preferences, facts | Cross-session |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Short-term: SQLite (dev), PostgreSQL (prod)\n",
    "- Long-term: PostgresStore with embeddings\n",
    "- Thread IDs manage sessions\n",
    "- Semantic search finds relevant memories\n",
    "- Memory tools enable save/retrieve operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "pg_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
