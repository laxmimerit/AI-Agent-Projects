{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Middleware Essentials\n",
    "\n",
    "Add production-ready middleware for message management, limits, fallbacks, and dynamic prompts.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Middleware adds production capabilities without changing agent logic\n",
    "- Trim messages keeps recent messages within context window\n",
    "- Delete messages removes specific or all messages from state\n",
    "- SummarizationMiddleware prevents context overflow with summaries\n",
    "- TodoListMiddleware provides task planning and tracking\n",
    "- Limits control costs and API usage\n",
    "- Fallbacks improve reliability\n",
    "- Dynamic prompts enable context-aware behavior\n",
    "- ShellToolMiddleware enables command execution\n",
    "- FilesystemFileSearchMiddleware provides file search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "# Setup checkpointer\n",
    "conn = sqlite3.connect(\"db/middleware_agent.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "checkpointer.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Messages\n",
    "\n",
    "Keep only recent messages to fit context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **Laxmi Kant**.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"trim_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is Laxmi Kant\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Messages\n",
    "\n",
    "Remove specific messages or clear entire history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Laxmi Kant.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import after_model\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # Remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"delete_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi! I'm Laxmi Kant\"}, config)\n",
    "response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummarizationMiddleware\n",
    "\n",
    "Automatically compress long conversations using summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=ChatGoogleGenerativeAI(model='gemini-2.5-flash'),\n",
    "            trigger=[(\"messages\", 15)],  # Summarize when > 15 messages\n",
    "            keep=(\"messages\", 5)  # Keep last 5 unsummarized\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'summary_session'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"Search for Apple, Microsoft, and Tesla stock news\"\n",
    "    )]\n",
    "}, config)\n",
    "\n",
    "len(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TodoListMiddleware\n",
    "\n",
    "Equip agents with task planning and tracking for complex multi-step tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': \"I created the file `test.txt` with the content 'Hello World' and then read it back. The content of the file is: 'Hello World'.\",\n",
       "  'extras': {'signature': 'CsEBAXLI2nyIB19MrS+AOeEEyL5712YVENaxwfKzYTBxk/JwYQtNvC/OEo0CVr0kxyazjd7NhVQLH8y0NHHbQ56CMcs8YxzaTo+gYZL7iMQbCJg0uaIctsRzi8XWd/KCpSlX4GyACk911lCe0/h37Q+SPvyHp5xhcNrM7OX6V7ebdVA+GEj2xN2XkRhEIooukryEgGztJOLhmu4/BLUgUcSjE2ee2W6C9UyQnRM1gNqNrzfgmFdvPCchqimpmCnJOIjZ+A=='}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def read_file(path: str):\n",
    "    \"\"\"Read file contents.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "@tool\n",
    "def write_file(path: str, content: str):\n",
    "    \"\"\"Write content to file.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully wrote to {path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing file: {e}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[read_file, write_file],\n",
    "    middleware=[TodoListMiddleware()],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'todo_session'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"Create a new file called test.txt with 'Hello World', then read it back\"\n",
    "    )]\n",
    "}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCallLimitMiddleware\n",
    "\n",
    "Prevent runaway costs by limiting model calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Please tell me the names of 5 companies you would like me to search for news about.',\n",
       "  'extras': {'signature': 'Cu8EAXLI2nxqGce9c/lBXz1/icZ/QTzPcQRFJZcxYWXmvD0tzFGyDq+meL7EAR/mEolUS8Yv7w+lUa10c323XIJYKpEuRSgX8Uqr13m8aBi47lXLCHlDKBJrDqTX6/hQVnUl19lnKXEtcLNnXTd5KyCvC7L8y/QONGnqeKgptkicDoSU7TbKXekvT/d/0eSVLpF1Whh5AMqp0cqoLsGo07k4V5OPNe+BIILz4IrjF4xB3jgXpg8JWPTNJhMYnExScSsdbLP/0Scq1v7uUUouqw1aX3AR3mi6Wwg17/NjvLGEX/8emU3aWRg9pcHywLmYJ8d+r/7DkrSDlqK38FOUv/OUjc9aKoS0ldNwWf9dJpJm4QPLSWANYkX0Kfp6MNnGZ9JJ2L4T1qAfH7RHR5qsjp+Vo+1A2+aEdl9kZ7R8ayCGGB8MNzsAWV2ZbLiBe8EEzyRqfBpVR/WU/OR64xZ5aMI4r1pys3ZGqyzj9MpEcV/QBmuKRhJlWHKp1CudpwkLDV48W8qLbYmlNFi093tJqZDbqzrv3h5oat2FicP9hUbSU62ByXIfr/b881vWs2RID1EsBsgq6PnLFwI4YNzrIR/8Uq5ZBLNsUguFKckkLjL4hePQy0Z+0oqI1bSp1lWxDjtdpztQ2SInbvjFZ6rJZFTkwXTRcyG92tyxrDi56FYiQB9HqD/Jt5dkc8qkV76Y9405vCJwq0AmO5RWvpgLGQsI1S6jdPhWiuDBa4snyUXz57dTnhY00oY2sp+aYDfVWx8vfbzbAnN/1XDE4iuHzgcORy+34O69yYGYIzVHp+3CLxu6/P1V3fwHwMPrcCIH/J4='}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[\n",
    "        ModelCallLimitMiddleware(\n",
    "            run_limit=2,  # Max 2 model calls\n",
    "            exit_behavior=\"end\"  # Stop when limit reached\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Search for news on 5 different companies\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToolCallLimitMiddleware\n",
    "\n",
    "Limit tool executions to manage API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': \"I was unable to retrieve news for Google due to a tool call limit. I can try again if you'd like.\\n\\nHere's a summary of the news for Apple and Microsoft:\\n\\n**Apple News:**\\n*   **Apple News+**: Get 3 months free with a new iPhone, iPad, or Mac. New subscribers get 1 month free, then $12.99/month. It's also included in the Apple One Premier plan.\\n*   Apple News+ offers access to over 500 leading publications, local, national, and international news, daily puzzles, and audio stories.\\n*   You can share your subscription with family, download issues for offline reading, and access it across various Apple devices (iPhone, Mac, iPad, CarPlay, HomePod, Apple Watch).\\n*   Apple News uses on-device intelligence for story recommendations and respects user privacy.\\n*   To view Apple News Top Stories, you need to open the link on an iPhone or iPad with iOS 9+ or a Mac with macOS 10.14+ and Apple News.\\n\\n**Microsoft News:**\\n*   **AI Capabilities for Retail**: Microsoft announced agentic AI solutions to bring intelligent automation to every part of the retail business, aiming to help retailers move faster, serve shoppers with greater relevance, and operate with resilience and efficiency.\\n*   **Copilot Checkout**: This feature allows shoppers to complete purchases directly within Copilot without being redirected to external sites, turning conversations into conversions. It's available in the U.S. on Copilot.com and supported by PayPal, Shopify, and Stripe. Brands like Urban Outfitters, Anthropologie, Ashley Furniture, and Etsy are participating.\\n*   **Intelligent Shopping Agents**: Microsoft is introducing Brand Agents (for Shopify merchants) and a personalized shopping agent template in Copilot Studio. These provide personalized, conversational shopping experiences, answer product questions, and drive conversions.\\n*   **Catalog Enrichment Agent Template**: In public preview, this intelligent assistant extracts product attributes from images, enriches them with social insights, and automates catalog tasks, fueling discovery and personalized shopping experiences.\\n*   **Store Operations Agent Template**: Also in public preview, this solution empowers store leaders and associates with a natural language interface for quick answers on inventory and policies, while autonomously orchestrating workflows and recommending actions.\\n*   **Global AI Adoption in 2025**: A report indicates that global adoption of generative AI continued to rise in the second half of 2025, with roughly one in six people worldwide using these tools. However, there's a widening digital divide, with adoption in the Global North growing nearly twice as fast as in the Global South. The UAE leads in AI usage.\",\n",
       "  'extras': {'signature': 'CqUBAXLI2nxwZsjItHGWITMxdNzbhINa6nrBQzxODhfRiuEnJXqXrk9q5dfsE/c82Gn4FNqEViXS7heY/oXfcb7oZVP7hxhU5D61J+qzR8PG008IhGjpTaPueSMdjBQFu5dEXWINQiI4RIFrQmfUFKUWf5ZPouPGkQSFY1K1NGasQhuDQ9S24uWVgY73XUZKtIPplLPA4jHCZAC+HLucleev9/iqadYH'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[\n",
    "        ToolCallLimitMiddleware(\n",
    "            run_limit=2,\n",
    "            exit_behavior=\"continue\"  # Continue without more tools\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Search for Apple, Microsoft, and Google news\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelFallbackMiddleware\n",
    "\n",
    "Fallback to alternate model on failure or for cost optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "fallback_model = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp')\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[ModelFallbackMiddleware(fallback_model)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic System Prompt\n",
    "\n",
    "Modify system prompt based on runtime context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest):\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"You are a helpful assistant.\"\n",
    "    \n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n",
    "    \n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Machine learning is a subset of artificial intelligence (AI) that enables systems to learn from data, identify patterns, and make decisions or predictions with minimal human intervention. Instead of being explicitly programmed for every task, machine learning algorithms are trained on large datasets, allowing them to \"learn\" and improve their performance over time.\\n\\nHere\\'s a breakdown of its core concepts:\\n\\n*   **Learning from Data:** The fundamental idea behind machine learning is to build models that can automatically discover insights and relationships within data. These models are exposed to vast amounts of data, which they analyze to find patterns, correlations, and structures.\\n*   **Algorithms:** Machine learning relies on various algorithms, which are sets of rules or instructions that the system follows to learn from data. Examples include linear regression, decision trees, support vector machines, neural networks, and k-means clustering.\\n*   **Models:** The output of a machine learning algorithm after training on data is called a model. This model can then be used to make predictions or decisions on new, unseen data.\\n\\n**Types of Machine Learning:**\\n\\n1.  **Supervised Learning:**\\n    *   **Concept:** The model learns from labeled data, meaning each input data point is paired with a corresponding correct output. The goal is for the model to learn a mapping from inputs to outputs.\\n    *   **Tasks:**\\n        *   **Classification:** Predicting a categorical label (e.g., spam or not spam, cat or dog).\\n        *   **Regression:** Predicting a continuous numerical value (e.g., house prices, stock prices).\\n    *   **Examples:** Image recognition, sentiment analysis, medical diagnosis.\\n\\n2.  **Unsupervised Learning:**\\n    *   **Concept:** The model learns from unlabeled data, meaning there are no pre-defined output labels. The goal is to discover hidden patterns, structures, or relationships within the data itself.\\n    *   **Tasks:**\\n        *   **Clustering:** Grouping similar data points together (e.g., customer segmentation).\\n        *   **Dimensionality Reduction:** Reducing the number of features in a dataset while retaining important information.\\n    *   **Examples:** Market segmentation, anomaly detection, topic modeling.\\n\\n3.  **Reinforcement Learning:**\\n    *   **Concept:** An agent learns to make decisions by interacting with an environment. It receives rewards for desirable actions and penalties for undesirable ones, aiming to maximize its cumulative reward over time.\\n    *   **Tasks:** Learning optimal policies for sequential decision-making.\\n    *   **Examples:** Game playing (e.g., AlphaGo), robotics, autonomous driving.\\n\\n**How it Works (Simplified):**\\n\\n1.  **Data Collection:** Gather relevant data.\\n2.  **Data Preprocessing:** Clean, transform, and prepare the data for the algorithm.\\n3.  **Model Training:** Feed the preprocessed data to a chosen machine learning algorithm. The algorithm adjusts its internal parameters to learn from the data.\\n4.  **Model Evaluation:** Test the trained model on new, unseen data to assess its performance and accuracy.\\n5.  **Deployment:** Once the model performs satisfactorily, it can be deployed to make predictions or decisions in real-world applications.\\n\\n**Applications of Machine Learning:**\\n\\n*   **Recommendation Systems:** Suggesting products, movies, or music (e.g., Netflix, Amazon).\\n*   **Spam Detection:** Identifying and filtering unwanted emails.\\n*   **Fraud Detection:** Flagging suspicious financial transactions.\\n*   **Natural Language Processing (NLP):** Language translation, chatbots, sentiment analysis.\\n*   **Computer Vision:** Facial recognition, object detection, medical image analysis.\\n*   **Healthcare:** Disease diagnosis, drug discovery.\\n*   **Finance:** Algorithmic trading, credit scoring.\\n\\nIn essence, machine learning empowers computers to learn and adapt without being explicitly programmed for every scenario, leading to increasingly intelligent and autonomous systems.',\n",
       "  'extras': {'signature': 'CvcDAXLI2nxMeH2GvyAXbje81mERmU8rFJbbGM+WmfpYcv6dvNGefExOPDPcN651ue2KZ9mLNElzcRCmjeDNDsGsbLeJBl8Vu3P3NOXM/qQ3anYHaOdWftNllT/o7pnWbLLl5yHoC7aCFrSEVXlI3e4Nfpd6X859vx+zY2lOzrSLXShrc4LaS/mnA0cOeKLlmcKcef40ufcgH1qNy6Ffo62LPZp1YdF890Dd+nhfIsAvfWttM7RuEOSng7R9SKCwMkdGgMmk8HauON1Zu1ad3KFlDAFEBdFqQRUJXjuh/ZsgBK0hRA47CVfQHOmCmAcS9ppTqnkH3H8rM0dIhaN6/y9HPL6dv50iS2UdpscQFYzaerHMAmRyh2DihKjUGIaUtBu0RPPT9KK5xxrseDsWmGF8pEP7YgnqG2phpFRVmlzOnbNLz7pi+vD9C/y7CTEGG6p72Qk+cwVYvDD458lJ8OcimYS5JacNXnn+FoGvas24JqXiPlU7ZBCB27QEseEx3FaKFxJ0wZykzVpsoA2pjgrjLELdmaibRf732UNflvJAxaKn0YU1anUrSJHYEKztyyihXBslk6rKXlMQIvgWzuFzKzNf5GLC3QyETFRLSpV3OStNHlNtc7o0gqZ7Rwzx6WoH61e9j1qdBsulYE75XkNMT7JEVV5qkE0='}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with expert context\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Imagine you want to teach a computer to recognize a cat in a picture. Instead of writing a long list of rules for every possible cat feature (like \"pointy ears,\" \"whiskers,\" \"furry\"), you can use machine learning.\\n\\nHere\\'s the basic idea:\\n\\n*   **Learning from examples:** You show the computer many pictures, some with cats and some without. For each picture, you tell the computer whether it contains a cat or not.\\n*   **Finding patterns:** The computer then analyzes these examples and tries to find patterns and relationships that help it tell the difference between cat pictures and non-cat pictures. It\\'s like the computer \"learns\" what a cat looks like on its own.\\n*   **Making predictions:** Once the computer has learned, you can show it a brand new picture it\\'s never seen before, and it will use what it learned to predict whether there\\'s a cat in that picture.\\n\\nIn simpler terms, **machine learning is a way of teaching computers to learn from data without being explicitly programmed for every single task.** Instead of giving them step-by-step instructions, you give them lots of examples, and they figure out the rules themselves.\\n\\nThis technology is used in many things you might encounter every day, like:\\n\\n*   **Spam filters:** Learning to identify unwanted emails.\\n*   **Recommendation systems:** Suggesting movies or products you might like.\\n*   **Voice assistants:** Understanding what you say.\\n*   **Self-driving cars:** Recognizing objects and making decisions on the road.',\n",
       "  'extras': {'signature': 'CsMCAXLI2nxW0IlTlmyoB8hSXSYach0HP3bX9ow6dD2jUtEcbbF7xhWi9LV5+3i2c3PfhQWdqO9GNMcH9Fuw0Wj5ru1xTxvqU9gHq27OXBeb8Mtv1XzJUsk6xBVM4AbSXS6aJl82hE4Nt8l5qldLRqsJCqbhBEkaG4I9742Ro1vT4bVfiIScELgDcWJFmwrsXf70yXlDFKhJcA3UItAsSERDyguu7p0VnuZ7YZl+SXdc0mx7woQi3St3JbbbyHDGsdS7SDBwZLm26X8MBHrkLYUd9+qxV2f1MQ49RmurdaPy3BAdhU6jLMALu6F3jfe+KsXOz9evAqGLea2EXlH6lQRcat8bw1OU19UUdu+a64YZxskXWeKqiehH9SENHVTpTyBEM2lhLNIHx4IQ08x86RF6za6X9giKipOZxDCKZtBNVvGKtZw='}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with beginner context\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShellToolMiddleware\n",
    "\n",
    "Expose persistent shell session for command execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting shell session failed; cleaning up resources.\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py\", line 676, in _create_resources\n",
      "    session.start()\n",
      "  File \"d:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py\", line 141, in start\n",
      "    self._process = self._policy.spawn(\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\_execution.py\", line 136, in spawn\n",
      "    process = _launch_subprocess(\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\_execution.py\", line 33, in _launch_subprocess\n",
      "    return subprocess.Popen(  # noqa: S603\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\laxmi\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\laxmi\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Basic shell with host execution\u001b[39;00m\n\u001b[32m      4\u001b[39m agent = create_agent(\n\u001b[32m      5\u001b[39m     model=model,\n\u001b[32m      6\u001b[39m     tools=[],\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ]\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mList files in the current directory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m response[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py:615\u001b[39m, in \u001b[36mShellToolMiddleware.before_agent\u001b[39m\u001b[34m(self, state, runtime)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbefore_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: ShellToolState, runtime: Runtime) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    614\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Start the shell session and run startup commands.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     resources = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_or_create_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mshell_session_resources\u001b[39m\u001b[33m\"\u001b[39m: resources}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py:654\u001b[39m, in \u001b[36mShellToolMiddleware._get_or_create_resources\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resources, _SessionResources):\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resources\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m new_resources = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# Cast needed to make state dict-like for mutation\u001b[39;00m\n\u001b[32m    656\u001b[39m cast(\u001b[33m\"\u001b[39m\u001b[33mdict[str, Any]\u001b[39m\u001b[33m\"\u001b[39m, state)[\u001b[33m\"\u001b[39m\u001b[33mshell_session_resources\u001b[39m\u001b[33m\"\u001b[39m] = new_resources\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py:676\u001b[39m, in \u001b[36mShellToolMiddleware._create_resources\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    669\u001b[39m session = ShellSession(\n\u001b[32m    670\u001b[39m     workspace_path,\n\u001b[32m    671\u001b[39m     \u001b[38;5;28mself\u001b[39m._execution_policy,\n\u001b[32m    672\u001b[39m     \u001b[38;5;28mself\u001b[39m._shell_command,\n\u001b[32m    673\u001b[39m     \u001b[38;5;28mself\u001b[39m._environment \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    674\u001b[39m )\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m     \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m     LOGGER.info(\u001b[33m\"\u001b[39m\u001b[33mStarted shell session in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, workspace_path)\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_startup_commands(session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\shell_tool.py:141\u001b[39m, in \u001b[36mShellSession.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process.poll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28mself\u001b[39m._process = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_policy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_workspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_environment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_command\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    147\u001b[39m     \u001b[38;5;28mself\u001b[39m._process.stdin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process.stdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process.stderr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    150\u001b[39m ):\n\u001b[32m    151\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mFailed to initialize shell session pipes.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\_execution.py:136\u001b[39m, in \u001b[36mHostExecutionPolicy.spawn\u001b[39m\u001b[34m(self, workspace, env, command)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mspawn\u001b[39m(\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    131\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     command: Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    135\u001b[39m ) -> subprocess.Popen[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     process = \u001b[43m_launch_subprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_preexec_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_process_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m._apply_post_spawn_limits(process)\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m process\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\Udemy\\AI Agent Projects\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\_execution.py:33\u001b[39m, in \u001b[36m_launch_subprocess\u001b[39m\u001b[34m(command, env, cwd, preexec_fn, start_new_session)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_launch_subprocess\u001b[39m(\n\u001b[32m     26\u001b[39m     command: Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     27\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     start_new_session: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m     32\u001b[39m ) -> subprocess.Popen[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: S603\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreplace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: PLW1509\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1554\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1555\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified",
      "During task with name 'ShellToolMiddleware.before_agent' and id '34f0aeeb-63e6-cd98-11ce-1922d275e26e'"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ShellToolMiddleware, HostExecutionPolicy\n",
    "\n",
    "# Basic shell with host execution\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"./workspace\",\n",
    "            execution_policy=HostExecutionPolicy(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"List files in the current directory\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shell with startup commands\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"./workspace\",\n",
    "            startup_commands=[\"echo 'Shell initialized'\"],\n",
    "            execution_policy=HostExecutionPolicy(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Create a directory called 'test_dir'\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FilesystemFileSearchMiddleware\n",
    "\n",
    "Provide Glob and Grep search tools over filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import FilesystemFileSearchMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        FilesystemFileSearchMiddleware(\n",
    "            root_path=\"../\",\n",
    "            use_ripgrep=True,\n",
    "            max_file_size_mb=10,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Find all Python files in this directory\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for specific content\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Find files containing 'create_agent'\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production agent with stacked middleware\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=ChatGoogleGenerativeAI(model='gemini-2.5-flash'),\n",
    "            trigger=[(\"messages\", 15)],\n",
    "            keep=(\"messages\", 5)\n",
    "        ),\n",
    "        TodoListMiddleware(),\n",
    "        ModelCallLimitMiddleware(run_limit=3, exit_behavior=\"end\"),\n",
    "        ToolCallLimitMiddleware(run_limit=3, exit_behavior=\"continue\"),\n",
    "        ModelFallbackMiddleware(fallback_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'production'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Analyze tech sector trends\")]\n",
    "}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
