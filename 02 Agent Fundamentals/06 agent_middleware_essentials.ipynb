{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Middleware Essentials\n",
    "\n",
    "Add production-ready middleware for message management, limits, fallbacks, and dynamic prompts.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Middleware adds production capabilities without changing agent logic\n",
    "- Trim messages keeps recent messages within context window\n",
    "- Delete messages removes specific or all messages from state\n",
    "- SummarizationMiddleware prevents context overflow with summaries\n",
    "- TodoListMiddleware provides task planning and tracking\n",
    "- Limits control costs and API usage\n",
    "- Fallbacks improve reliability\n",
    "- Dynamic prompts enable context-aware behavior\n",
    "- ShellToolMiddleware enables command execution\n",
    "- FilesystemFileSearchMiddleware provides file search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "\n",
    "# Setup checkpointer\n",
    "conn = sqlite3.connect(\"db/middleware_agent.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "checkpointer.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Messages\n",
    "\n",
    "Keep only recent messages to fit context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **Laxmi Kant**.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"trim_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is Laxmi Kant\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Messages\n",
    "\n",
    "Remove specific messages or clear entire history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Laxmi Kant.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import after_model\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # Remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"delete_session\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi! I'm Laxmi Kant\"}, config)\n",
    "response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummarizationMiddleware\n",
    "\n",
    "Automatically compress long conversations using summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=ChatGoogleGenerativeAI(model='gemini-2.5-flash'),\n",
    "            trigger=[(\"messages\", 15)],  # Summarize when > 15 messages\n",
    "            keep=(\"messages\", 5)  # Keep last 5 unsummarized\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'summary_session'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"Search for Apple, Microsoft, and Tesla stock news\"\n",
    "    )]\n",
    "}, config)\n",
    "\n",
    "len(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TodoListMiddleware\n",
    "\n",
    "Equip agents with task planning and tracking for complex multi-step tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': \"I created the file `test.txt` with the content 'Hello World' and then read it back. The content of the file is: 'Hello World'.\",\n",
       "  'extras': {'signature': 'CsEBAXLI2nyIB19MrS+AOeEEyL5712YVENaxwfKzYTBxk/JwYQtNvC/OEo0CVr0kxyazjd7NhVQLH8y0NHHbQ56CMcs8YxzaTo+gYZL7iMQbCJg0uaIctsRzi8XWd/KCpSlX4GyACk911lCe0/h37Q+SPvyHp5xhcNrM7OX6V7ebdVA+GEj2xN2XkRhEIooukryEgGztJOLhmu4/BLUgUcSjE2ee2W6C9UyQnRM1gNqNrzfgmFdvPCchqimpmCnJOIjZ+A=='}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def read_file(path: str):\n",
    "    \"\"\"Read file contents.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "@tool\n",
    "def write_file(path: str, content: str):\n",
    "    \"\"\"Write content to file.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully wrote to {path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing file: {e}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[read_file, write_file],\n",
    "    middleware=[TodoListMiddleware()],\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'todo_session'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"Create a new file called test.txt with 'Hello World', then read it back\"\n",
    "    )]\n",
    "}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "# Define basic and advanced models\n",
    "basic_model = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "advanced_model = ChatGoogleGenerativeAI(model='gemini-3-flash-preview')\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler):\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    \n",
    "    if message_count > 10:\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "    \n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[dynamic_model_selection]\n",
    ")\n",
    "\n",
    "response = agent.invoke({'messages': [HumanMessage(\"What is AI?\")]})\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCallLimitMiddleware\n",
    "\n",
    "Prevent runaway costs by limiting model calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Please tell me the names of 5 companies you would like me to search for news about.',\n",
       "  'extras': {'signature': 'Cu8EAXLI2nxqGce9c/lBXz1/icZ/QTzPcQRFJZcxYWXmvD0tzFGyDq+meL7EAR/mEolUS8Yv7w+lUa10c323XIJYKpEuRSgX8Uqr13m8aBi47lXLCHlDKBJrDqTX6/hQVnUl19lnKXEtcLNnXTd5KyCvC7L8y/QONGnqeKgptkicDoSU7TbKXekvT/d/0eSVLpF1Whh5AMqp0cqoLsGo07k4V5OPNe+BIILz4IrjF4xB3jgXpg8JWPTNJhMYnExScSsdbLP/0Scq1v7uUUouqw1aX3AR3mi6Wwg17/NjvLGEX/8emU3aWRg9pcHywLmYJ8d+r/7DkrSDlqK38FOUv/OUjc9aKoS0ldNwWf9dJpJm4QPLSWANYkX0Kfp6MNnGZ9JJ2L4T1qAfH7RHR5qsjp+Vo+1A2+aEdl9kZ7R8ayCGGB8MNzsAWV2ZbLiBe8EEzyRqfBpVR/WU/OR64xZ5aMI4r1pys3ZGqyzj9MpEcV/QBmuKRhJlWHKp1CudpwkLDV48W8qLbYmlNFi093tJqZDbqzrv3h5oat2FicP9hUbSU62ByXIfr/b881vWs2RID1EsBsgq6PnLFwI4YNzrIR/8Uq5ZBLNsUguFKckkLjL4hePQy0Z+0oqI1bSp1lWxDjtdpztQ2SInbvjFZ6rJZFTkwXTRcyG92tyxrDi56FYiQB9HqD/Jt5dkc8qkV76Y9405vCJwq0AmO5RWvpgLGQsI1S6jdPhWiuDBa4snyUXz57dTnhY00oY2sp+aYDfVWx8vfbzbAnN/1XDE4iuHzgcORy+34O69yYGYIzVHp+3CLxu6/P1V3fwHwMPrcCIH/J4='}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[\n",
    "        ModelCallLimitMiddleware(\n",
    "            run_limit=2,  # Max 2 model calls\n",
    "            exit_behavior=\"end\"  # Stop when limit reached\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Search for news on 5 different companies\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToolCallLimitMiddleware\n",
    "\n",
    "Limit tool executions to manage API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': \"I was unable to retrieve news for Google due to a tool call limit. I can try again if you'd like.\\n\\nHere's a summary of the news for Apple and Microsoft:\\n\\n**Apple News:**\\n*   **Apple News+**: Get 3 months free with a new iPhone, iPad, or Mac. New subscribers get 1 month free, then $12.99/month. It's also included in the Apple One Premier plan.\\n*   Apple News+ offers access to over 500 leading publications, local, national, and international news, daily puzzles, and audio stories.\\n*   You can share your subscription with family, download issues for offline reading, and access it across various Apple devices (iPhone, Mac, iPad, CarPlay, HomePod, Apple Watch).\\n*   Apple News uses on-device intelligence for story recommendations and respects user privacy.\\n*   To view Apple News Top Stories, you need to open the link on an iPhone or iPad with iOS 9+ or a Mac with macOS 10.14+ and Apple News.\\n\\n**Microsoft News:**\\n*   **AI Capabilities for Retail**: Microsoft announced agentic AI solutions to bring intelligent automation to every part of the retail business, aiming to help retailers move faster, serve shoppers with greater relevance, and operate with resilience and efficiency.\\n*   **Copilot Checkout**: This feature allows shoppers to complete purchases directly within Copilot without being redirected to external sites, turning conversations into conversions. It's available in the U.S. on Copilot.com and supported by PayPal, Shopify, and Stripe. Brands like Urban Outfitters, Anthropologie, Ashley Furniture, and Etsy are participating.\\n*   **Intelligent Shopping Agents**: Microsoft is introducing Brand Agents (for Shopify merchants) and a personalized shopping agent template in Copilot Studio. These provide personalized, conversational shopping experiences, answer product questions, and drive conversions.\\n*   **Catalog Enrichment Agent Template**: In public preview, this intelligent assistant extracts product attributes from images, enriches them with social insights, and automates catalog tasks, fueling discovery and personalized shopping experiences.\\n*   **Store Operations Agent Template**: Also in public preview, this solution empowers store leaders and associates with a natural language interface for quick answers on inventory and policies, while autonomously orchestrating workflows and recommending actions.\\n*   **Global AI Adoption in 2025**: A report indicates that global adoption of generative AI continued to rise in the second half of 2025, with roughly one in six people worldwide using these tools. However, there's a widening digital divide, with adoption in the Global North growing nearly twice as fast as in the Global South. The UAE leads in AI usage.\",\n",
       "  'extras': {'signature': 'CqUBAXLI2nxwZsjItHGWITMxdNzbhINa6nrBQzxODhfRiuEnJXqXrk9q5dfsE/c82Gn4FNqEViXS7heY/oXfcb7oZVP7hxhU5D61J+qzR8PG008IhGjpTaPueSMdjBQFu5dEXWINQiI4RIFrQmfUFKUWf5ZPouPGkQSFY1K1NGasQhuDQ9S24uWVgY73XUZKtIPplLPA4jHCZAC+HLucleev9/iqadYH'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[\n",
    "        ToolCallLimitMiddleware(\n",
    "            run_limit=2,\n",
    "            exit_behavior=\"continue\"  # Continue without more tools\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Search for Apple, Microsoft, and Google news\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelFallbackMiddleware\n",
    "\n",
    "Fallback to alternate model on failure or for cost optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash')\n",
    "fallback_model = ChatGoogleGenerativeAI(model='gemini-3-flash-preview')\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[ModelFallbackMiddleware(fallback_model)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic System Prompt\n",
    "\n",
    "Modify system prompt based on runtime context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest):\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"You are a helpful assistant.\"\n",
    "    \n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n",
    "    \n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Machine learning is a subset of artificial intelligence (AI) that enables systems to learn from data, identify patterns, and make decisions or predictions with minimal human intervention. Instead of being explicitly programmed for every task, machine learning algorithms are trained on large datasets, allowing them to \"learn\" and improve their performance over time.\\n\\nHere\\'s a breakdown of its core concepts:\\n\\n*   **Learning from Data:** The fundamental idea behind machine learning is to build models that can automatically discover insights and relationships within data. These models are exposed to vast amounts of data, which they analyze to find patterns, correlations, and structures.\\n*   **Algorithms:** Machine learning relies on various algorithms, which are sets of rules or instructions that the system follows to learn from data. Examples include linear regression, decision trees, support vector machines, neural networks, and k-means clustering.\\n*   **Models:** The output of a machine learning algorithm after training on data is called a model. This model can then be used to make predictions or decisions on new, unseen data.\\n\\n**Types of Machine Learning:**\\n\\n1.  **Supervised Learning:**\\n    *   **Concept:** The model learns from labeled data, meaning each input data point is paired with a corresponding correct output. The goal is for the model to learn a mapping from inputs to outputs.\\n    *   **Tasks:**\\n        *   **Classification:** Predicting a categorical label (e.g., spam or not spam, cat or dog).\\n        *   **Regression:** Predicting a continuous numerical value (e.g., house prices, stock prices).\\n    *   **Examples:** Image recognition, sentiment analysis, medical diagnosis.\\n\\n2.  **Unsupervised Learning:**\\n    *   **Concept:** The model learns from unlabeled data, meaning there are no pre-defined output labels. The goal is to discover hidden patterns, structures, or relationships within the data itself.\\n    *   **Tasks:**\\n        *   **Clustering:** Grouping similar data points together (e.g., customer segmentation).\\n        *   **Dimensionality Reduction:** Reducing the number of features in a dataset while retaining important information.\\n    *   **Examples:** Market segmentation, anomaly detection, topic modeling.\\n\\n3.  **Reinforcement Learning:**\\n    *   **Concept:** An agent learns to make decisions by interacting with an environment. It receives rewards for desirable actions and penalties for undesirable ones, aiming to maximize its cumulative reward over time.\\n    *   **Tasks:** Learning optimal policies for sequential decision-making.\\n    *   **Examples:** Game playing (e.g., AlphaGo), robotics, autonomous driving.\\n\\n**How it Works (Simplified):**\\n\\n1.  **Data Collection:** Gather relevant data.\\n2.  **Data Preprocessing:** Clean, transform, and prepare the data for the algorithm.\\n3.  **Model Training:** Feed the preprocessed data to a chosen machine learning algorithm. The algorithm adjusts its internal parameters to learn from the data.\\n4.  **Model Evaluation:** Test the trained model on new, unseen data to assess its performance and accuracy.\\n5.  **Deployment:** Once the model performs satisfactorily, it can be deployed to make predictions or decisions in real-world applications.\\n\\n**Applications of Machine Learning:**\\n\\n*   **Recommendation Systems:** Suggesting products, movies, or music (e.g., Netflix, Amazon).\\n*   **Spam Detection:** Identifying and filtering unwanted emails.\\n*   **Fraud Detection:** Flagging suspicious financial transactions.\\n*   **Natural Language Processing (NLP):** Language translation, chatbots, sentiment analysis.\\n*   **Computer Vision:** Facial recognition, object detection, medical image analysis.\\n*   **Healthcare:** Disease diagnosis, drug discovery.\\n*   **Finance:** Algorithmic trading, credit scoring.\\n\\nIn essence, machine learning empowers computers to learn and adapt without being explicitly programmed for every scenario, leading to increasingly intelligent and autonomous systems.',\n",
       "  'extras': {'signature': 'CvcDAXLI2nxMeH2GvyAXbje81mERmU8rFJbbGM+WmfpYcv6dvNGefExOPDPcN651ue2KZ9mLNElzcRCmjeDNDsGsbLeJBl8Vu3P3NOXM/qQ3anYHaOdWftNllT/o7pnWbLLl5yHoC7aCFrSEVXlI3e4Nfpd6X859vx+zY2lOzrSLXShrc4LaS/mnA0cOeKLlmcKcef40ufcgH1qNy6Ffo62LPZp1YdF890Dd+nhfIsAvfWttM7RuEOSng7R9SKCwMkdGgMmk8HauON1Zu1ad3KFlDAFEBdFqQRUJXjuh/ZsgBK0hRA47CVfQHOmCmAcS9ppTqnkH3H8rM0dIhaN6/y9HPL6dv50iS2UdpscQFYzaerHMAmRyh2DihKjUGIaUtBu0RPPT9KK5xxrseDsWmGF8pEP7YgnqG2phpFRVmlzOnbNLz7pi+vD9C/y7CTEGG6p72Qk+cwVYvDD458lJ8OcimYS5JacNXnn+FoGvas24JqXiPlU7ZBCB27QEseEx3FaKFxJ0wZykzVpsoA2pjgrjLELdmaibRf732UNflvJAxaKn0YU1anUrSJHYEKztyyihXBslk6rKXlMQIvgWzuFzKzNf5GLC3QyETFRLSpV3OStNHlNtc7o0gqZ7Rwzx6WoH61e9j1qdBsulYE75XkNMT7JEVV5qkE0='}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with expert context\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'Imagine you want to teach a computer to recognize a cat in a picture. Instead of writing a long list of rules for every possible cat feature (like \"pointy ears,\" \"whiskers,\" \"furry\"), you can use machine learning.\\n\\nHere\\'s the basic idea:\\n\\n*   **Learning from examples:** You show the computer many pictures, some with cats and some without. For each picture, you tell the computer whether it contains a cat or not.\\n*   **Finding patterns:** The computer then analyzes these examples and tries to find patterns and relationships that help it tell the difference between cat pictures and non-cat pictures. It\\'s like the computer \"learns\" what a cat looks like on its own.\\n*   **Making predictions:** Once the computer has learned, you can show it a brand new picture it\\'s never seen before, and it will use what it learned to predict whether there\\'s a cat in that picture.\\n\\nIn simpler terms, **machine learning is a way of teaching computers to learn from data without being explicitly programmed for every single task.** Instead of giving them step-by-step instructions, you give them lots of examples, and they figure out the rules themselves.\\n\\nThis technology is used in many things you might encounter every day, like:\\n\\n*   **Spam filters:** Learning to identify unwanted emails.\\n*   **Recommendation systems:** Suggesting movies or products you might like.\\n*   **Voice assistants:** Understanding what you say.\\n*   **Self-driving cars:** Recognizing objects and making decisions on the road.',\n",
       "  'extras': {'signature': 'CsMCAXLI2nxW0IlTlmyoB8hSXSYach0HP3bX9ow6dD2jUtEcbbF7xhWi9LV5+3i2c3PfhQWdqO9GNMcH9Fuw0Wj5ru1xTxvqU9gHq27OXBeb8Mtv1XzJUsk6xBVM4AbSXS6aJl82hE4Nt8l5qldLRqsJCqbhBEkaG4I9742Ro1vT4bVfiIScELgDcWJFmwrsXf70yXlDFKhJcA3UItAsSERDyguu7p0VnuZ7YZl+SXdc0mx7woQi3St3JbbbyHDGsdS7SDBwZLm26X8MBHrkLYUd9+qxV2f1MQ49RmurdaPy3BAdhU6jLMALu6F3jfe+KsXOz9evAqGLea2EXlH6lQRcat8bw1OU19UUdu+a64YZxskXWeKqiehH9SENHVTpTyBEM2lhLNIHx4IQ08x86RF6za6X9giKipOZxDCKZtBNVvGKtZw='}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with beginner context\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain machine learning\"}]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShellToolMiddleware\n",
    "\n",
    "Expose persistent shell session for command execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command timed out after 30.00 seconds; restarting shell session.\n",
      "Command timed out after 30.00 seconds; restarting shell session.\n",
      "Command timed out after 30.00 seconds; restarting shell session.\n",
      "Command timed out after 30.00 seconds; restarting shell session.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'I am unable to list the files in the current directory. The `dir` command is consistently timing out. There seems to be an issue with the shell environment preventing commands from completing.',\n",
       "  'extras': {'signature': 'CrMEAXLI2nzx/Uc3Q/XV3vHOA7dsjENT3bAFwg/4YoE/sDcvWxMtv4MwoDwsupDRCxAqM+PNaXSH/gwoIqmHOfqYdC9Qw0GEjrn/VJQGkzrCbq/fu8tS1R/KVpgzOYneCbPpiUDyzHDaB3GWw8ZxkSGhYY/tTqSwrUqcK5NqUjoPMCxoMSHJL4AgCXSNHHsBC5EyqM9J/GpDQeQeIJE8Tzg0T0unNrrYrB5tiF18/17lQ5fzFSZF8eJTqI9eZ0hH8PUSXjogntpnShojVD4XVWKnVUFYM3qztgdih7XbW9Bm3beHSTgFh7UOG6eyM0SYZw1huF8sgBDwoZmg88hGB9ShzMCm+J6cB7/hO2JESOt4ok2tvPBt5jgC2kobGHCQju8FjZ+N8nvjaI2TkiR673dEumGIKhC01gWqikVgfvAR40C9m1w/09h4JJHYHwVWjU/yFHOgaiqQ8Xfhv8HiJGGF2x5bXUfwwLPR2OZMDz1/yBiN/ApPhoGliM3ekCJN3dqrctl1kg6Qrz0ue8lx4+jeKlc26F+MZDT5zo5hgFDQN77N2BfL757ak7YujDFjogUpJHTPy7EqvhSV4iOzrX3CATFhyPZ5AeV7XwRHYGSRbqUUUhdA3UfqkAjVyKFFPBU9pRFLdALpMCV6AUah3RPNJl9Ts827vFoK9OwgySOodh1DrPmH9mYdPmmj/E4xeEohf9Eagvw3MjP/SIDKWWHJyMhVP/UoJe7ON8wSDf1b3cQAIm0='}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import ShellToolMiddleware, HostExecutionPolicy\n",
    "\n",
    "system_prompt = \"\"\"You are running on Windows. Only use Windows CMD commands. \n",
    "                Never use ls, cat, head, tail, grep, or pipes. \n",
    "                Use dir, type, findstr, etc. \"\"\"\n",
    "\n",
    "# Basic shell with host execution\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=system_prompt,\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"./workspace\",\n",
    "            execution_policy=HostExecutionPolicy(\n",
    "                create_process_group=False\n",
    "            ),\n",
    "            shell_command=[\"cmd.exe\", \"/k\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"List files in the current directory\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shell with startup commands\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"./workspace\",\n",
    "            startup_commands=[\"echo 'Shell initialized'\"],\n",
    "            execution_policy=HostExecutionPolicy(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Create a directory called 'test_dir'\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FilesystemFileSearchMiddleware\n",
    "\n",
    "Provide Glob and Grep search tools over filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import FilesystemFileSearchMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        FilesystemFileSearchMiddleware(\n",
    "            root_path=\"../\",\n",
    "            use_ripgrep=True,\n",
    "            max_file_size_mb=10,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Find all Python files in this directory\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for specific content\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Find files containing 'create_agent'\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production agent with stacked middleware\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=ChatGoogleGenerativeAI(model='gemini-3-pro-preview'),\n",
    "            trigger=[(\"messages\", 15)],\n",
    "            keep=(\"messages\", 5)\n",
    "        ),\n",
    "        TodoListMiddleware(),\n",
    "        ModelCallLimitMiddleware(run_limit=3, exit_behavior=\"end\"),\n",
    "        ToolCallLimitMiddleware(run_limit=3, exit_behavior=\"continue\"),\n",
    "        ModelFallbackMiddleware(fallback_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 'production'}}\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Analyze tech sector trends\")]\n",
    "}, config)\n",
    "\n",
    "response['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
