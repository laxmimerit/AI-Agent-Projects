{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Tools and Configurations\n",
    "\n",
    "Tools give agents ability to take actions: sequential/parallel calls, error handling, and state persistence.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Tools extend agent capabilities with actions\n",
    "- @wrap_tool_call handles errors gracefully\n",
    "- Agent selects tools based on docstrings\n",
    "- Sequential vs parallel execution determined by model\n",
    "- Clear tool descriptions guide selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from scripts import base_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash', include_thoughts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perform a live web search using Ollama Cloud Web Search API for real-time information and news.\\n\\nInput:\\n    query: search query string\\n\\nOutput:\\n    JSON string of top results (max_results=2).'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Tool Name and Description\n",
    "base_tools.web_search.name\n",
    "\n",
    "base_tools.web_search.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Agent with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Tokyo is Sunny with a temperature of 15°C. The wind is from the SW at 39.6 kph, and the humidity is 36%.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"What's the weather in Tokyo?\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent without tools - single LLM node\n",
    "agent = create_agent(model=model, tools=[])\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"Hello\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a summary of recent Apple news:\\n\\nApple recently held its **Worldwide Developers Conference (WWDC 2024)**, where it unveiled significant updates across its platforms:\\n\\n*   **Apple Intelligence:** A new personal AI system deeply integrated into iOS 18, iPadOS 18, and macOS Sequoia, focusing on privacy, personalization, and productivity features like enhanced writing tools, image generation, and a more powerful Siri.\\n*   **iOS 18:** Major updates including home screen customization, a redesigned Control Center, a new Photos app experience, and enhancements to Messages.\\n*   **macOS Sequoia:** Introduces iPhone Mirroring, new Safari features, and gaming improvements.\\n*   **visionOS 2:** Updates for Apple Vision Pro, including new spatial photos capabilities and gestures.\\n*   **watchOS 11:** Features a new Vitals app, training load measurement, and customizable Smart Stack.\\n*   **Vision Pro International Expansion:** Apple Vision Pro is expanding to several new countries, including China, Japan, Singapore, Australia, Canada, France, Germany, and the UK.\\n*   **Ongoing Regulatory Scrutiny:** Apple continues to navigate antitrust challenges, including the ongoing U.S. Department of Justice lawsuit.\\n\\n***\\n\\nAnd now for the weather in **Cupertino, California** (as of my last update):\\n\\n*   **Current Temperature:** 68°F (20°C)\\n*   **Conditions:** Partly Cloudy\\n*   **Humidity:** 60%\\n*   **Wind:** 5 mph from the West\\n*   **Today's High/Low:** High 75°F (24°C) / Low 55°F (13°C)\\n*   **Forecast:** Expect partly cloudy skies throughout the day with a gentle breeze.\\n\\n*(Note: Weather information can change rapidly. For the most up-to-the-minute details, please check a live weather source.)*\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent calls tools in sequence\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"Search for Apple news, then tell me weather in Cupertino\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's the current weather for Paris and London:\\n\\n*   **Paris, France:**\\n    It's currently around **15°C (59°F)** with **partly cloudy skies**. There's a light breeze, and humidity is moderate.\\n\\n*   **London, UK:**\\n    It's a bit cooler at around **13°C (55°F)** and currently experiencing **light rain**. Humidity is higher, and there's a moderate breeze.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent may call tools in parallel (independent requests)\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\n",
    "        \"What's the weather in Paris and London?\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Division by zero is not possible.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain.tools import tool\n",
    "# Tool WITHOUT internal error handling\n",
    "@tool\n",
    "def divide(a: float, b: float):\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return a / b  # This will crash on division by zero\n",
    "\n",
    "# Middleware catches it and returns graceful error to model\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        return ToolMessage(\n",
    "            content=f\"Error: {str(e)}. Try different input.\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[base_tools.web_search, base_tools.get_weather, divide],\n",
    "    middleware=[handle_tool_errors]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [HumanMessage(\"what is 1/0?\")]\n",
    "})\n",
    "\n",
    "response['messages'][-1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Context - State Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import ToolRuntime\n",
    "from langchain_core.messages import AIMessage\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Tool that retrieves the count of messages in conversation\n",
    "@tool\n",
    "def get_message_count(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the total number of messages exchanged in the conversation.\"\"\"\n",
    "    messages = runtime.state[\"messages\"]\n",
    "\n",
    "    # Access context as attribute (not dictionary)\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    return f\"User [{user_id}] history have '{len(messages)}' messages\"\n",
    "\n",
    "@tool\n",
    "def get_token_count(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the actual token usage from AI responses.\"\"\"\n",
    "    messages = runtime.state[\"messages\"]\n",
    "    \n",
    "    # Access context as attribute (not dictionary)\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    # Track token usage from AI messages\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    total_tokens = 0\n",
    "    response_count = 0\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            # Extract usage_metadata if available\n",
    "            if hasattr(msg, 'usage_metadata') and msg.usage_metadata:\n",
    "                total_input_tokens += msg.usage_metadata.get('input_tokens', 0)\n",
    "                total_output_tokens += msg.usage_metadata.get('output_tokens', 0)\n",
    "                total_tokens += msg.usage_metadata.get('total_tokens', 0)\n",
    "                response_count += 1\n",
    "    \n",
    "    return f\"\"\"USER ID: {user_id} \n",
    "                AI responses: {response_count}\n",
    "                Input tokens: {total_input_tokens}\n",
    "                Output tokens: {total_output_tokens}\n",
    "                Total tokens: {total_tokens}\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_message_count, get_token_count],\n",
    "    context_schema=UserContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how many messages i have?', additional_kwargs={}, response_metadata={}, id='32c921c2-2a3c-42be-b18c-31320d120dcf'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_message_count', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'5f5b86fa-0e0b-4f0c-995f-969c9eb8e4f4': 'CssBAXLI2nx30fFuy8S3NxLuIIEgsE09JwZAi6IA2ThA8OJ6WT0+oK5uooM76+EPdup57A+nP400r7UstSCXjX23dyct+0V+eEZGVXCaYcXWyDFafYguQ0MMr+razTPCfhcvm4+Z7/uECOcoSDJlEvTE8mrhc3TzYyoPgkiyAzPIGUdm6rjjxxMuPgZURx0BVC4YrVNQrfdcJKKYrGYVaOxOU+zBSLAQScXEVs2fJb20rCx1XP1fG5/oK8rZBYbbenKLoK5jS/+murwQ49k='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb5fd-f185-79a2-a498-82ffb0054a64-0', tool_calls=[{'name': 'get_message_count', 'args': {}, 'id': '5f5b86fa-0e0b-4f0c-995f-969c9eb8e4f4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 73, 'output_tokens': 51, 'total_tokens': 124, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 39}}),\n",
       "  ToolMessage(content=\"User [user_123] has '2' messages\", name='get_message_count', id='241ab8df-b328-4121-b162-5972045b452d', tool_call_id='5f5b86fa-0e0b-4f0c-995f-969c9eb8e4f4'),\n",
       "  AIMessage(content='You have 2 messages.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb5fd-f8aa-7603-a111-9c7c3ec6436d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 114, 'output_tokens': 6, 'total_tokens': 120, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        HumanMessage(\"how many messages i have?\")\n",
    "    ]\n",
    "}, context=UserContext(user_id=\"user_123\"))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how many tokens i have?', additional_kwargs={}, response_metadata={}, id='b3ad7e73-cba7-4839-84f3-5fe8491bd135'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_token_count', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'5254d736-6d09-4707-9d8d-e3e1fe601340': 'CucBAXLI2nygKX3Ltg95/dQnPv45oYa2TXpynvbNumIMf5uypmg0JjqVYsd772e1wzalNpka1qMhs6gQmSlIprtMzki/sdjFQZKkj8a+9szXmzZuGEjH+ft48pZu8FJSLnDTCvfitWpe/rQqfZN+Us1Vn5TLd9ACjm27vEbMk3eqdbk2yasT8+sG0fb9yRAlhOybquSPFR71BqCzko0Kye7FDdZvV2bRNSpaWtAN6Mlx3EbKB4MwR6epKxLh8c6Q20RhYPglUgy7R34/IrtfYimSLvtq+dmm8YjXE5mdamV+BxbxaXxs9nic'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb5f1-c026-7812-9522-edf9abda7c75-0', tool_calls=[{'name': 'get_token_count', 'args': {}, 'id': '5254d736-6d09-4707-9d8d-e3e1fe601340', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 73, 'output_tokens': 58, 'total_tokens': 131, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 46}}),\n",
       "  ToolMessage(content='USER ID: user_123 \\n                AI responses: 1\\n                Input tokens: 73\\n                Output tokens: 58\\n                Total tokens: 131', name='get_token_count', id='e7c3d94a-9cc1-4ab6-9667-6e6f2b8ef886', tool_call_id='5254d736-6d09-4707-9d8d-e3e1fe601340'),\n",
       "  AIMessage(content='You have 131 tokens in total, with 73 tokens for input and 58 tokens for output.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bb5f1-c82c-7400-b8c3-75275dad4c17-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 25, 'total_tokens': 170, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        HumanMessage(\"how many tokens i have?\")\n",
    "    ]\n",
    "}, context=UserContext(user_id=\"user_123\"))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
